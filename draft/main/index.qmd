---
title: "Computational Tool Choice Impacts CRISPR Spacer-Protospacer Detection"
author:
  - name: Uri Neri*^1^
    corresponding: true
  - name: Antonio Pedro Camargo^1^
  - name: Brian Bushnell^1^
  - name: Rick Beeloo^2^
  - name: Simon Roux^1^
format:
  pdf:
    documentclass: article
    geometry:
      - margin=1in
    fig-format: pdf
    embed-resources: true
    keep-tex: true
    fig-pos: 'H'
    number-sections: true
    cite-method: biblatex
    bibliography: references.bib
    pdf-engine: xelatex
  html:
    toc: true
    toc-depth: 3
    number-sections: true
  docx: default
execute:
  echo: false
  warning: false
jupyter: python3
---

1: DOE Joint Genome Institute, Berkeley, CA, USA\
2: Utrecht University, Padualaan 8, Utrecht, NL 3584 CH\
\* Uri Neri (uneri\@lbl.gov)

## Abstract {#sec-abstract}

CRISPR (Clustered Regularly Interspaced Short Palindromic Repeats) systems are a fundamental defense mechanism in prokaryotes, where short sequences called spacers are stored in the host genome to recognize and target exogenous genetic elements. Viromics, the study of viral communities in environmental samples, relies heavily on identifying these spacer-target interactions to understand host-virus relationships. However, the choice of sequence search tool to identify putative spacer targets is often overlooked, leading to an unknown impact of downstream inferences in virus-host analysis. Here, we utilize simulated and real datasets to compare popular sequence alignment and search tools, revealing critical differences in their ability to detect potential matches and handle varying degrees of sequence identity between spacers and potential targets. Finally, we provide general guidelines that may inform future research regarding matching, which is a common practice in studying the complex nature of host-MGE interactions.

## Introduction {#sec-introduction}

CRISPR (clustered regularly interspaced short palindromic repeats) systems play a vital role in prokaryotic defense against mobile genetic elements, including viruses, plasmids, and other autonomous genetic elements [@Mojica_2005; @CRISPR_review]. These systems are organized as arrays in the bacteria or archaea genome, where short sequences called spacers are interspersed between repeated sequences. The spacer sequences within these arrays guide the targeting of invasive genetic elements, allowing for specific defense against these threats [@CRISPR_classification]. The corresponding locus on the virus genome where the spacer complements is termed "protospacer". The analysis of spacer-protospacer pairs is essential in understanding the complex interactions between hosts and MGEs [@Edwards2015_phage_host]. Beyond their natural role in prokaryotic immunity, CRISPR systems have been adapted into powerful gene-editing frameworks for biotechnology and therapeutic applications [@CRISPR_gene_editing_review], though the computational considerations for analyzing natural CRISPR-mediated phage-host interactions differ substantially from predicting off-target effects in gene editing contexts, as discussed below.

The identification of genuine host-MGE interactions through spacer-protospacer matching presents unique challenges due to the dynamic nature of these relationships and the complexity of sequence evolution. While matches between spacers and protospacers are often interpreted as evidence of interaction, various biological and technical factors can complicate this interpretation [@Edwards2015_phage_host; @soto_perez_crispr_2019].

Several key scenarios can lead to false positive assignments in spacer-protospacer matching. Low complexity sequences can create spurious matches between simple repeat regions (albeit these can be mitigated through complexity filtering such as tantan [@Frith_2010] or DUST [@Morgulis_2006]). Another type of potential false positives are highly conserved sequences shared by unrelated MGEs, potentially resulting from horizontal gene transfer between MGEs. The horizontal transfer of CRISPR arrays themselves on mobile elements further requires careful examination of array genomic context (regions outside the CRISPR loci) and phylogenetic analysis. Self-targeting events, where matches occur against the host genome rather than MGEs, necessitate comparison against host genome databases and analysis of targeting context [@Stern_2010]. Finally, historical acquisition events may not reflect current interactions, requiring consideration of phylogenetic dating, evolution rates and the effects of the protospacers being under selective pressure to mutate (which may reduce the MGE susceptibility to deterioration by the CRISPR system). This is further complicated by the fact that increasing the allowed distance between sequences directly increases the likelihood of identifying non-related sequences as similar (sharing high nucleic identity) to each other.

False negatives present another challenge in spacer-protospacer matching, particularly when dealing with large databases of potential targets. Many alignment and search tools default to reporting only the best (top) matches or the first matches that pass a given threshold for a given query or HSP. This may result in potentially missing additional legitimate matches. Unfortunately, different tools also handle ambiguous or secondary alignments differently: they may be reported completely, reported up to a number or based on relative alignment quality, or omitted. Similarly, cases where a query sequence has multiple equally scoring matches in different reference sequences are not handled uniformly across tools. This limitation becomes increasingly problematic as databases grow larger and more diverse, a single spacer might match (implying a targeting) multiple related MGEs.

Yet despite these variations, the choice of spacer-to-protospacer search or alignment tool is often not deeply considered. Presently, the common option for this task, popularized by Edwards et al and Biswas et al [@Edwards2015_phage_host; @Biswas2013], uses BLASTn [@Altschul1990_blast] with parameters adjusted for short input sequences. However as for most bioinformatic tools, the exact workflow design and parameter choice can impact the outcome, including in sequence analysis. The importance of proper tool usage and parameter interpretation is highlighted by historical examples in bioinformatics. A striking example is the work of Shah et al, @Shah2018, in which they report how certain misunderstandings of BLAST's `-max_target_seqs` parameter may lead to incorrect assumptions about result completeness, potentially impacting published analyses. Albeit this was later clarified by Madden et al., [@Madden2018] (of the blast development team) as an unfortunate combination of a software bug (that were since patched) affecting rare cases, and misconceptions regarding the process BLAST+ uses for tie-breaking (alignments of equal plausibility), and finally a consideration regarding composition base scoring. Apart from the patched bug, the main outcome of this correspondence led to more explicit details in blast documentation (specifically the appendix "Outline of the BLAST process"). Still, this highlights that misconceptions about the expected exhaustiveness of tools' result-reporting can also lead to incorrect assumptions about the outcome of an analysis. In practice, most bioinformatic tools use various heuristics and optimizations, typically designed with specific use cases in mind. For example, most short-read mappers assume the reference to be the output of a singular assembly - which would imply the reference does not contain extremely redundant copies of the same nucleic regions, or a limited number of very similar sequences (e.g. strain variants, alternative splice variants), and this assumption impacts the way read mapping is computed and results are reported.

The choice of tool and its parameters can significantly impact the detection of these multiple matches, with some tools prioritizing speed over completeness by limiting the number of reported matches, or by other internal heuristics such as seed sequence selection from high occurring sequences being penalized. This trade-off between sensitivity and computational efficiency is especially important to consider as most available tools were designed for different tasks than spacer-protospacer matching (e.g. expression analysis, homology detection, and variant calling), and under different assumptions (such as reference and query sequence size and database size or the nature of the reference source: from a single isolate or metagenomic sample rather than from aggregation of sequences from different sources).

**Computational Foundations of Sequence Similarity:**

From a computer science perspective, biological sequences are represented as strings of characters drawn from finite alphabets: DNA and RNA sequences use the four-letter nucleobase alphabet (A, U/T, G, C), while protein sequences use the twenty-letter amino acid alphabet. Determining sequence similarity thus becomes a string matching problem, where the goal is to find all occurrences of a query string (or similar variants) within a reference string or database, subject to specified constraints on permitted differences. The fundamental challenge lies in defining (and efficiently computing) a meaningful notion of "similarity" between sequences that may have diverged through evolutionary processes including substitutions, insertions, deletions, and rearrangements.

The classical computational approach to sequence alignment employs dynamic programming algorithms, most notably the Needleman-Wunsch algorithm for global alignment [@Needleman1970_global_alignment] and the Smith-Waterman algorithm for local alignment [@Smith1981_local_alignment]. These algorithms guarantee optimal alignments under a given scoring scheme but operate with $O(mn)$ time complexity, where $m$ and $n$ are the lengths of the two sequences being compared. When searching a query of length $m$ against a database of total length $N$, exhaustive application of dynamic programming requires $O(mN)$ operations. For modern metagenomic databases where $N$ can exceed $10^{11}$ bases and query sets may contain millions of spacers, this quadratic scaling becomes computationally prohibitive. For instance, searching 3.8 million spacers (total length \$\sim$132 Mbp) against the IMG/VR4 database ($\sim\$79 Gbp) would require approximately $10^{19}$ operations if using exhaustive pairwise comparisons, translating to centuries of computation time even on modern hardware.

Exhaustive methods that guarantee perfect recall (sensitivity = 1.0) within specified distance thresholds do exist for specific use cases. Tools like Sassy employ bit-parallel algorithms based on Myers' algorithm [@Myers1999_bitparallel] to achieve exhaustive approximate string matching with arbitrary edit distance thresholds, while indelfree.sh (in bruteforce mode) provides exhaustive hamming distance matching. These approaches are valuable for validation and ground truth establishment on small datasets, but their computational costs scale poorly.

**Heuristic Algorithms and Their Goal-Driven Design:**

To achieve practical performance on large datasets, virtually all widely-used sequence alignment tools employ heuristic algorithms that sacrifice guaranteed completeness for dramatic improvements in speed. These heuristics are fundamentally goal-driven: they are often designed and optimized for specific biological questions and use cases, with algorithmic choices reflecting assumptions about the expected characteristics of both queries and references. Understanding these design constraints is essential when purposing tools for applications outside their intended scope.

Heuristic sequence search tools typically employ multi-stage filtering architectures. BLAST [@Altschul1990_blast], perhaps the most widely used sequence search tool, uses a seed-and-extend strategy: it identifies short exact matches ("seeds" or "words") between query and database sequences, then extends these seeds using gapped alignment only in promising regions. The seed length, extension threshold, and statistical framework (E-values based on extreme value distribution) are all calibrated for detecting homologs across diverse sequence databases. Modern short-read mappers use similar principles but with different optimizations: Bowtie1 employs FM-index data structures enabling efficient exact substring matching followed by backtracking to allow mismatches [@Langmead2009_bowtie]; Bowtie2 extends this with a multiseed heuristic and affine gap penalties [@Langmead2012_bowtie2]; Minimap2 uses minimizer-based sparse seeding combined with chaining algorithms to handle long reads with higher error rates [@Li2018_minimap2]; StrobeAlign employs randstrobes (hash-based linked k-mers) to improve seed specificity [@Sahlin2022_strobealign]. Tools designed for large-scale homology searches like MMseqs2 use cascaded k-mer filtering: sequences must share sufficient k-mer matches to pass initial filtering before undergoing more expensive alignment [@Steinegger2017_mmseqs2].

Critically, these heuristics introduce reporting biases and completeness limitations that vary depending on database composition and query characteristics. Many tools employ early termination strategies, reporting only the top $k$ matches or the first matches passing a threshold, which can lead to missing equally valid (within alignment thresholds set) alternative alignments. Smart seed selection may penalize high-frequency k-mers to reduce computational burden from repetitive regions, potentially causing reduced sensitivity for highly abundant targets. Some tools may assume references derive from single-source assemblies and optimize for unique best-hit assignment rather than comprehensive multi-mapping detection. These design choices, while appropriate for the tools' intended applications, currently have unknown impact in the context of spacer-protospacer matching, where queries are short (typically within 25-65 bp), searched across diverse reference sequences often comprised of multiple potential hosts genomes and mobile genetic elements (which may share genes), where a comprehensive detection of all valid matches should be considered.

**Distance Metrics and Their Biological Interpretation:**

Tools differ fundamentally in how they measure sequence similarity, employing different distance metrics that reflect distinct evolutionary models. Hamming distance counts only substitutions and requires sequences of equal length, making it appropriate for scenarios where length-changing mutations are rare or highly deleterious. Edit distance (Levenshtein distance) allows insertions and deletions in addition to substitutions, reflecting a broader evolutionary model. Affine gap distance extends edit distance by assigning different penalties to gap opening versus gap extension, better modeling the biological reality that indels often occur in clusters. Finally, some applications require exact matching with zero tolerance for differences.

Importantly, when comparing tools using different distance metrics with the same numeric threshold (e.g., "≤3 mismatches"), edit/gap-affine-based algorithms will naturally report more matches than hamming-based ones because they solve a more permissive computational problem (). This reflects different definitions of sequence similarity rather than differences in tool quality. Hence, the choice of distance metric should be driven by the biological question and system being studied.

**Distance Metric Choice and Experimental Evidence:**

For CRISPR spacer-protospacer matching in natural systems, the choice between hamming distance and edit distance has both biological and computational implications. This benchmark addresses spacer-protospacer matching in the context of inferring historical phage-host interactions in natural prokaryotic populations, which differs fundamentally from predicting CRISPR off-target effects in gene editing applications. In natural systems, we aim to identify evolutionary relationships since protospacer acquisition, where sequence divergence reflects selective pressure on MGEs to mutate and "escape" host defenses. For gene editing applications, even partial base-pairing (including alignments with indels) can cause unwanted off-target cleavage, necessitating more permissive distance metrics. Similarly, when working with low-accuracy sequencing data (e.g., Oxford Nanopore R9 chemistry [@ONT_R9_accuracy]) or analyzing raw reads rather than assembled contigs (made from sufficient sequencing depth), some tolerance for indels may be necessary to account for sequencing errors, as the alignment quality cannot exceed the underlying data quality.

Experimental studies consistently report that phage escape mutations from CRISPR immunity are predominantly single nucleotide substitutions, particularly in the PAM-proximal "seed" region where mismatches have the strongest effect on targeting. Foundational work by Deveau et al. [@Deveau2008] demonstrated that phages escape CRISPR immunity in *Streptococcus thermophilus* through point mutations in protospacers. Semenova et al. [@Semenova2011] established that in *E. coli* type I-E CRISPR-Cas system, a seven-nucleotide seed region immediately following the PAM is critical for targeting, with mutations in this seed region abolishing immunity by reducing crRNA-guided Cascade complex binding affinity. Fineran et al. [@Fineran2014] further showed that phages readily escape through point mutations in the PAM or seed region. More recently, Schelling et al. [@Schelling2023] demonstrated that phage escape occurs mainly through mutations in PAM and seed regions, with preexisting mismatches at any target location accelerating emergence of mutant phages. Across these experimental systems, escape mutations are consistently reported as single nucleotide polymorphisms rather than indels. Bacterial (the host) mutation rates typically have indels occurring approximately 10× [@Lee_2012_mutation_rate_Ecoli] less frequently than substitutions (albeit some extreme outliers have been reported such as \~3× less likely (26% of total mutations) in *Acidobacterium capsulatum* [@Kucukyildirim_2021_high_indel_rate]), and this trend is expected to be similar or more pronounced in phage genomes. Similar to their host, phage transcriptional units often contain several genes with small intragenic spaces [@Hatfull_2011_bacteriophages_genomes], often resulting in a particularly coding-dense genome with coding genes occupying most of the genomes (e.g. as demonstrated by Ha et al for multiple diverse phage families,coding sequences occupy on average \>\$92.4% of the entire genome [@Ha_2018]). The lower indel rates align with the fact that while frameshift-inducing indels are particularly deleterious, substitutions may affect only a single amino acid residue. Frame-preserving indels (multiples of 3 bp) are extremely rare but, when observed, may be particularly strong indicators of selection (to our knowledge, no previous study has reported this, although we observed this phenomena anecdotally, see Supplementary Note 2). We acknowledge that most existing literature focuses on substitutions, potentially stemming from substitutions being easier to detect and characterize than indels, or a potential "assumption of expected" bias where the lack of reports about indel escape mutations may not translate to it being a less frequent phenomena. Indeed, a systematic quantitative comparisons of mutation type frequencies across diverse phage-host systems remain lacking. The only report of a verified indel escape mutation we were able to find is from a study by Paez-Espino et al, [@Paez_Espino_2015]. In that long-term coevolution experiment with *S. thermophilus* phage 2972, the authors note in the methods section "Finally, postassembly as well as comparative analyses were performed to identify SNPs, indels, and recombination events", however indels (or gaps) are not mentioned in the main text discussing escape mechanisms, and only a single indel event is listed in the supplemental "Table S5. Phage 2972 targeting" among the escape mutations identified, suggesting even this relatively large experimental setup is not adequate to observe enough varied mutations required for statistical analysis. Of note, the authors report, another type of esacpe mutation - large genomic rearrangments and recombination events. Viral genomes are considered higly mosaic, where genes are commonly exchanged between which are particularly common in phage genomes [@Hatfull_2011_bacteriophages_genomes; @Kupczok_2018_phage_genome_evolution]. While such rearrangement escape mutation are particuarly interesting, we argue that in the context of sequence search tools, these would not be detectable under either hamming nor edit distance metrics, as the original biologically targeted region is either discarded (replaced by protein of similar function, but not necceraly similar nucleic sequence), or split and repositioned in different loci (in the case of internal rearrangement, such as the original spacer targeted the edge between two subsequent genes that underwent synteny altering rearrangement).

**False Positives in Sequence Similarity Searches:**

A critical consideration in sequence similarity searches is the expected rate of spurious matches arising by chance rather than true biological relationships. Traditionally, false positives in sequence similarity searches are considered as matches that appear similar by standard alignment metrics but arise from convergent evolution, random sequence similarity, or compositional biases rather than common ancestry or functional relationships (note: in our Methods and Results sections we define false positives very differently, as we lack ground truth for evolutionary relationships; see Methods). For random DNA sequences of equal nucleotide composition, the probability of finding an exact match of length $L$ is approximately $(1/4)^L$, suggesting exact matches should be extremely rare. However, this simple model fails to capture biological reality: sequences are not random and exhibit compositional biases (GC content variation), low-complexity regions (simple repeats, homopolymers), and conserved functional elements that can create spurious similarities, or similarities arising from convergent evolution rather than shared ancestry.

Most sequence search tools employ statistical frameworks to estimate false positive rates. BLAST calculates E-values representing the expected number of matches with a given score occurring by chance in a database of specified size, based on extreme value distribution theory [@Altschul1990_blast]. This framework assumes sequences are i.i.d. (independent and identically distributed) random samples, an assumption violated by real biological sequences. Low-complexity filtering tools like DUST [@Morgulis_2006] and tantan [@Frith_2010] attempt to mask repetitive regions that contribute disproportionately to spurious matches. However, determining what constitutes a "true" versus "false" positive is particulary chellenging in the absence of ground truth. For short sequences, this is further complicated: firstly, less positions in the alignment imply less information (e.g. the difference in likelihood as more positions are similar in both subject and query), and secondly, as the space of possible matches is very large even under low distance thresholds, and these are often searched in large genomic databases. Noteably, both viral and spacer databases have been routinely increasing in size in recent years: as CRISPR spacer databases have grown from 366,799 unique spacers in 2017 [@Shmakov_2017] to 3,835,942 in 2023 [@camargo_img_vr4_2023]. This increase is largely attributed to progress in metagenomic sequencing.

**Computational Resource Considerations:**

Another important consideration is computational resource requirements. Memory, storage, and availability of CPU cores are factors differing between tools. Parameter choice may also impact these factors considerably, with certain tools offering tunable parameters to trade-off between sensitivity and computational efficiency. In recent years, spacer database size has been rapidly increasing - from 366,799 unique spacers in 2017 [@Shmakov_2017] to 1,173,006 unique spacers reported in 2021 [@Dion_2021] to 3,835,942 unique spacers in 2023 [@camargo_img_vr4_2023]. Similarly, public virus and MGE databases are growing rapidly, with large contributions from metagenomic samples resulting in routine fold increases in the number of predicted viral contigs [@camargo_img_vr4_2023]. Most tools require more resources as the size of the database grows, and as this trend continues, certain workflows and tools may become prohibitively expensive to run in a reasonable time frame.

## Methods {#sec-methods}

### Tool Selection {#sec-tool-selection}

We evaluated several widely-used sequence alignment and search tools, spanning different algorithmic approaches and computational strategies (table 1). The tools were selected based on their availability, historical use in sequence analysis, and diversity of algorithmic approaches. The selection includes both exhaustive methods (Sassy, indelfree.sh in bruteforce mode) that guarantee finding all matches within specified distance thresholds, and heuristic methods that use various optimizations for improved speed.

It is important to note that most of these tools were not specifically designed for CRISPR spacer-protospacer matching, but rather for more general sequence search tasks (MMseqs2, BLASTn-short), alignment/mapping of short reads to reference genomes (Bowtie1, Bowtie2, Minimap2, MUMmer4, StrobeAlign, X-mapper), or versatile pattern matching (Sassy, indelfree.sh). Our focus is specifically on spacer-to-protospacer sequence matching as a bioinformatics task, and we did not evaluate integrated host-prediction tools like SpacePHARER [@Zhang_2021] or iPHoP [@Roux2023_iphop], which perform additional analyses such as phylogenetic evaluation or LCA determination from multiple spacer-protospacer matches.

All tools were configured to maximize sensitivity and avoid artificial limitations on multiple match detection. Some tools required specific parameter adjustments to enable detection of short sequences (e.g., BLASTn-short task, Bowtie1/2 short read modes) or to report all matches rather than only top hits. The exhaustive tools (Sassy, indelfree.sh bruteforce mode) were included specifically to validate the completeness of heuristic tool results on smaller datasets where computational costs remain feasible.

+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Aligner                                                                        | Indexing | Main Algorithm                                                                                                   | Heuristic/Exhaustive                                                                                                                           | Reporting/Limiting Threshold Used in Benchmark | Year                                            | Original Purpose /\                                                                                                 | Notes                                                                                                                                                                                               |
|                                                                                |          |                                                                                                                  |                                                                                                                                                |                                                |                                                 | intended use                                                                                                        |                                                                                                                                                                                                     |
+:===============================================================================+:========:+:=================================================================================================================+:===============================================================================================================================================+:===============================================+:===============================================:+:====================================================================================================================+:====================================================================================================================================================================================================+
| [Bowtie1](https://github.com/BenLangmead/bowtie)                               | Yes      | FM-Index (BWT)                                                                                                   | Yes (backtracking)                                                                                                                             | Hamming distance                               | 2009                                            | Short read mapping                                                                                                  | Optimized for 25-50 bp reads (max 1kbp); ungapped alignment only; backtracking heuristic limits to 3 mismatches                                                                                     |
+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [Bowtie2](https://github.com/BenLangmead/bowtie2)                              | Yes      | FM-Index (BWT)                                                                                                   | Yes (multiseed + extend)                                                                                                                       | Affine/Edit distance                           | 2012                                            | Read mapping                                                                                                        | Uses FM-index for seeding with SIMD-accelerated DP extension; supports gapped, local, and end-to-end alignment                                                                                      |
+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [Minimap2](https://github.com/lh3/minimap2)                                    | Optional | Minimizer + chaining                                                                                             | Yes (minimizer seeding)                                                                                                                        | Edit distance                                  | 2018                                            | Long read mapping                                                                                                   | Lexicographically smallest k-mer per window; collinear chaining with gap penalties; versatile across read types                                                                                     |
+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [indelfree.sh](https://github.com/bbushnell/BBTools/)                          | No       | Multi-kmer matching                                                                                              | Bruteforce mode is exhaustive, while ion "Indexed" mode this can be limited by selected kmer length, query length, and number of substitutions | Hamming distance                               | Publically introduced to bbtools September 2025 | Read mapping                                                                                                        | BBTools suite is Java based, and will use available memory - so the peak memory reported herein (sourced from SLURM logs) does not equate with "minimal required memory"                            |
+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [StrobeAlign](https://github.com/ksahlin/StrobeAlign)                          | Yes      | Randstrobes                                                                                                      | Yes (syncmer thinning)                                                                                                                         | Edit distance                                  | 2022                                            | Read mapping                                                                                                        | Uses hash-based linked strobes (randstrobes) with multi-context seeds (MCS) for hierarchical search                                                                                                 |
+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [BLAST+](https://blast.ncbi.nlm.nih.gov/doc/blast-help/downloadblastdata.html) | Optional | Hit-and-extend                                                                                                   | Yes (contiguous word)                                                                                                                          | E-value, bit score                             | 2009                                            | Sequence search                                                                                                     | BLASTN-short mode uses 11-mer seeds; reports matches based on e-value (expected hits by chance given DB size)                                                                                       |
+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [MMseqs2](https://github.com/soedinglab/MMseqs2)                               | Optional | K-mer prefiltering                                                                                               | Yes (3-stage cascade)                                                                                                                          | E-value, bit score                             | 2017                                            | Sequence search                                                                                                     | Double k-mer matching → vectorized ungapped → gapped SW; optimized for many-against-many searches                                                                                                   |
+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [Sassy](https://github.com/RagnarGrootKoerkamp/sassy)                          | No       | Uses a bit-parallel algorithm based on Myers' bitpacking to perform exhaustive approximate string matching (ASM) | Exhaustive                                                                                                                                     | Edit distance                                  | 2025                                            | Versatile pattern matching, suggested for use in CRISPR (gene-editing) off target detection and raw-read alignments | Guarantees perfect recall; explores full edit distance landscape; supports arbitrary distances; high computational cost, requires SIMD instructions (AVX2 and NEON), which most modern CPUs support |
+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [X-mapper](https://github.com/mathjeff/Mapper)                                 | Yes      | Gapped x-mer pyramid                                                                                             | Yes (dynamic seeds)                                                                                                                            | Edit distance                                  | 2024                                            | Read mapping                                                                                                        | **Preprint** - Dynamic-length gapped x-mers with "pyramid walking" to optimize seed specificity                                                                                                     |
+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [mummer4](https://github.com/mummer4/mummer)                                   | Optional | 48-bit suffix array                                                                                              | Yes (MUM-based)                                                                                                                                | Edit distance                                  | 2018                                            | Genome alignment                                                                                                    | Identifies Maximal Unique Matches (MUMs) using enhanced suffix array; handles genomes up to 141 Tbp                                                                                                 |
+--------------------------------------------------------------------------------+----------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------+-------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

: Evaluated Tools and Their Characteristics. **Indexing:** "Yes" indicates a pre-computed index is required (in our benchmark, if an index has to be pre-created the time to construct it is measured along the search/alignment step); "Optional" means a persistent index can be generated for reuse but the tool can also build it on-the-fly for single runs; "No" means no indexing is required or supported. **Heuristic/Exhaustive:** Exhaustive methods guarantee finding all matches within the specified distance threshold; heuristic methods use optimizations (seed-based indexing, chaining, k-mer filtering) to improve speed but may miss some matches. **Reporting/Limiting Threshold:** The primary metric used to report or filter alignments. Hamming distance counts only substitutions; Edit distance allows insertions and deletions; Affine distance uses gap penalties; E-value represents expected matches by chance given database size; Exact match requires perfect identity. Note that edit/affine-based algorithms will naturally report more matches than hamming-based ones when both use the same numeric threshold—this reflects different computational problems being solved rather than tool quality differences. **Tool Configuration:** All tools were configured to maximize sensitivity and avoid artificial limitations on multiple match detection. Exact commands, parameters, and tool versions are provided in Supplementary Table S1. {#tbl-tools}

### Data Generation and acquisition {#sec-data}

We evaluated tool performance using three complementary approaches with varying levels of ground truth information:

+---------------------+------------------------+---------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Dataset Type**    | **Spacers**            | **Spacer Stats**                                        | **Contig Stats**                                                                                                                                                                                                                                                                                                                                                                                          | **Notes**                                                                                                                                                                                                                                                                                                                                   |
+=====================+========================+=========================================================+===========================================================================================================================================================================================================================================================================================================================================================================================================+=============================================================================================================================================================================================================================================================================================================================================+
| **Fully Synthetic** | 100-500k simulated     | 25-45 bp range; GC 49%                                  | 5,000-100k simulated \| 10-550 kbp range; normal distribution; GC 46%                                                                                                                                                                                                                                                                                                                                     | Complete ground truth; 8 datasets varying in size (50k-500k spacers × 5k-100k contigs); enables comprehensive validation across different scales; planned insertions (1-5 per spacer, or 100-2,500 for high-insertion variant) with 0-5 mismatches; all tools on smaller sets (≤5 hamming), heuristic tools only on largest (≤3 hamming) \| |
+---------------------+------------------------+---------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Semi-Synthetic**  | 3,826,979 real (iPHoP) | 132 Mbp total; 25-100 bp range; median 34 bp; GC 46.73% | 421,431 simulated                                                                                                                                                                                                                                                                                                                                                                                         | \~11.2 Gbp total; 2-100 kbp range; normal distribution; GC 46% \| Real spacers + synthetic contigs matching IMG/VR4 characteristics; 0 planned insertions to estimate non-planned match rates; heuristic tools only (≤3 hamming) due to size \| \|                                                                                          |
+---------------------+------------------------+---------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                     |                        |                                                         |                                                                                                                                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                             |
+---------------------+------------------------+---------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Real Data\        | 3,835,942 real (iPHoP) | 132 Mbp total; 25-100 bp range; median 34 bp; GC 46.73% | 421,431 HQ contigs \| xxx Gbp total; 1,001-xxx bp range; median 7,664 bp; GC 44.45% \| Real-world performance; HQ subset from 5.1M filtered contigs; subsampled at 0.0005× (279 contigs, 7 Mbp), 0.001× (421 contigs, 10 Mbp), 0.005× (2.1k contigs, 57 Mbp), 0.01× (4.2k contigs, 124 Mbp), 0.05× (21k contigs, 715 Mbp), 0.1× (42k contigs, 1.5 Gbp), and 1× (421k contigs, 18.9 Gbp) \| \| \| \| \| \| |                                                                                                                                                                                                                                                                                                                                             |
| (IMG/VR4)**         |                        |                                                         |                                                                                                                                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                             |
+---------------------+------------------------+---------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

: Dataset characteristics and ground truth availability. Synthetic contigs were generated to match IMG/VR4 sequence characteristics (GC content, length distributions). Subsampling of IMG/VR4 HQ contigs enabled inclusion of exhaustive tools on smaller fractions while evaluating all tools on larger fractions and the full HQ dataset.

+---------------------+------------------------+---------------------------------------------------------+-------------------------------+-----------------------------------------------+----------+
| Dataset Type        | Spacers                | Spacer Stats                                            | Contigs                       | Contigs Stats                                 | Notes    |
+=====================+========================+=========================================================+===============================+===============================================+==========+
| Fully Synthetic     | 100-500k               | 25-45 bp range; GC 49%                                  | 5,000-100k                    | 10-550 kbp range; normal distribution; GC 46% |          |
+---------------------+------------------------+---------------------------------------------------------+-------------------------------+-----------------------------------------------+----------+
| Semi-Synthetic      | 3,826,979 real (iPHoP) | 132 Mbp total; 25-100 bp range; median 34 bp; GC 46.73% | 400k (simulated)              | 2-100 kbp range; normal distribution; GC 46%  |          |
+---------------------+------------------------+---------------------------------------------------------+-------------------------------+-----------------------------------------------+----------+
| Real Data (IMG/VR4) | 3,826,979 real (iPHoP) | 132 Mbp total; 25-100 bp range; median 34 bp; GC 46.73% | 421,431 (High Quality subset) |                                               |          |
+---------------------+------------------------+---------------------------------------------------------+-------------------------------+-----------------------------------------------+----------+
|                     |                        |                                                         |                               |                                               |          |
+---------------------+------------------------+---------------------------------------------------------+-------------------------------+-----------------------------------------------+----------+
|                     |                        |                                                         |                               |                                               |          |
+---------------------+------------------------+---------------------------------------------------------+-------------------------------+-----------------------------------------------+----------+

: Dataset characteristics and ground truth availability. Synthetic contigs were generated to match IMG/VR4 sequence characteristics (GC content, length distributions). Subsampling of IMG/VR4 HQ contigs enabled inclusion of exhaustive tools on smaller fractions while evaluating all tools on larger fractions and the full HQ dataset.

The sequence statistics for the datasets (spacers and contigs) are detailed in the table below. The "fraction_X_contigs" datasets represent the subsampled fractions of the IMG/VR4 HQ contigs, while the "ns_X_nc_Y_spacers/contigs" datasets represent the various synthetic datasets generated for benchmarking. Note that the "ns_3826979_nc_421431_real_baseline_spacers/contigs" datasets are semi-synthetic, where real spacers were injected into simulated contigs matching the characteristics of the real IMG/VR4 HQ contigs. \| Dataset \| num_seqs \| sum_len \| min_len \| avg_len \| max_len \| N50 \| N50_num \| GC(%) \| sum_n \| \|--------------------------------------------\|----------\|-------------\|---------\|----------\|---------\|--------\|---------\|-------\|--------\| \| fraction_0.0005_contigs \| 279 \| 7036591 \| 1060 \| 25220.8 \| 233373 \| 42913 \| 52 \| 47.7 \| 109 \| \| fraction_0.001_contigs \| 421 \| 9745671 \| 1700 \| 23148.9 \| 246318 \| 41316 \| 79 \| 47.03 \| 81 \| \| fraction_0.005_contigs \| 2107 \| 57059412 \| 1060 \| 27080.9 \| 618736 \| 46117 \| 377 \| 46.28 \| 513 \| \| fraction_0.01_contigs \| 4214 \| 123668270 \| 1060 \| 29347 \| 482156 \| 46893 \| 794 \| 46.6 \| 1511 \| \| fraction_0.05_contigs \| 21071 \| 715073062 \| 1060 \| 33936.4 \| 505259 \| 48794 \| 4090 \| 46.44 \| 8395 \| \| fraction_0.1_contigs \| 42143 \| 1504536616 \| 1060 \| 35700.7 \| 596785 \| 49299 \| 8229 \| 46.45 \| 15911 \| \| fraction_1_contigs \| 421431 \| 18870643188 \| 1060 \| 44777.5 \| 711471 \| 50703 \| 51773 \| 46.28 \| 190416 \| \| iphop_filtered_spacers \| 3826979 \| 129494053 \| 25 \| 33.8 \| 40 \| 34 \| 7 \| 47.6 \| 0 \| \| ns_100000_nc_10000_spacers \| 100000 \| 3201222 \| 25 \| 32 \| 40 \| 32 \| 9 \| 49.02 \| 0 \| \| ns_100000_nc_20000_spacers \| 100000 \| 3200186 \| 25 \| 32 \| 40 \| 32 \| 9 \| 48.98 \| 0 \| \| ns_100_nc_50000_spacers \| 100 \| 3568 \| 25 \| 35.7 \| 45 \| 37 \| 9 \| 48.85 \| 0 \| \| ns_500000_nc_100000 \| 500000 \| 16002956 \| 25 \| 32 \| 40 \| 32 \| 9 \| 49.03 \| 0 \| \| ns_50000_nc_5000_spacers \| 50000 \| 1599652 \| 25 \| 32 \| 40 \| 32 \| 9 \| 49.07 \| 0 \| \| ns_500_nc_5000_HIGH_INSERTION_RATE_spacers \| 500 \| 16007 \| 25 \| 32 \| 39 \| 32 \| 8 \| 48.94 \| 0 \| \| ns_75000_nc_5000_spacers \| 75000 \| 2401592 \| 25 \| 32 \| 40 \| 32 \| 9 \| 48.96 \| 0 \| \| ns_100000_nc_10000_contigs \| 10000 \| 802832723 \| 10067 \| 80283.3 \| 149921 \| 86884 \| 3658 \| 49 \| 0 \| \| ns_100000_nc_20000_contigs \| 20000 \| 1604143975 \| 10014 \| 80207.2 \| 149390 \| 86557 \| 6999 \| 49 \| 0 \| \| ns_100_nc_50000_contigs \| 50000 \| 21317765741 \| 4446 \| 426355.3 \| 849632 \| 471189 \| 18014 \| 46 \| 0 \| \| ns_3826979_nc_421431_real_baseline_contigs \| 421431 \| 21470981225 \| 2006 \| 50947.8 \| 100000 \| 55952 \| 32988 \| 46 \| 0 \| \| ns_500000_nc_100000_contigs \| 100000 \| 28002479279 \| 10140 \| 280024.8 \| 549926 \| 307966 \| 33074 \| 49 \| 0 \| \| ns_50000_nc_5000_contigs \| 5000 \| 402606570 \| 11391 \| 80521.3 \| 149534 \| 86780 \| 1894 \| 49 \| 0 \| \| ns_500_nc_5000_HIGH_INSERTION_RATE_contigs \| 5000 \| 400779688 \| 11241 \| 80155.9 \| 149479 \| 86447 \| 1890 \| 49.01 \| 0 \| \| ns_75000_nc_5000_contigs \| 5000 \| 401074812 \| 10244 \| 80215 \| 149609 \| 87005 \| 1893 \| 49 \| 0 \| : seqs.

Dataset num_seqs sum_len min_len avg_len max_len N50 N50_num GC(%) sum_n fraction_0.0005_contigs 279 7036591 1060 25220.8 233373 42913 52 47.7 109 fraction_0.001_contigs 421 9745671 1700 23148.9 246318 41316 79 47.03 81 fraction_0.005_contigs 2107 57059412 1060 27080.9 618736 46117 377 46.28 513 fraction_0.01_contigs 4214 123668270 1060 29347 482156 46893 794 46.6 1511 fraction_0.05_contigs 21071 715073062 1060 33936.4 505259 48794 4090 46.44 8395 fraction_0.1_contigs 42143 1504536616 1060 35700.7 596785 49299 8229 46.45 15911 fraction_1_contigs 421431 18870643188 1060 44777.5 711471 50703 51773 46.28 190416 iphop_filtered_spacers 3826979 129494053 25 33.8 40 34 7 47.6 0 ns_100000_nc_10000_spacers 100000 3201222 25 32 40 32 9 49.02 0 ns_100000_nc_20000_spacers 100000 3200186 25 32 40 32 9 48.98 0 ns_100_nc_50000_spacers 100 3568 25 35.7 45 37 9 48.85 0 ns_3826979_nc_421431_real_baseline_spacers 3826979 129494053 25 33.8 40 34 7 47.6 0 ns_500000_nc_100000 500000 16002956 25 32 40 32 9 49.03 0 ns_50000_nc_5000_spacers 50000 1599652 25 32 40 32 9 49.07 0 ns_500_nc_5000_HIGH_INSERTION_RATE_spacers 500 16007 25 32 39 32 8 48.94 0 ns_75000_nc_5000_spacers 75000 2401592 25 32 40 32 9 48.96 0 ns_100000_nc_10000_contigs 10000 802832723 10067 80283.3 149921 86884 3658 49 0 ns_100000_nc_20000_contigs 20000 1604143975 10014 80207.2 149390 86557 6999 49 0 ns_100_nc_50000_contigs 50000 21317765741 4446 426355.3 849632 471189 18014 46 0 ns_3826979_nc_421431_real_baseline_contigs 421431 21470981225 2006 50947.8 100000 55952 32988 46 0 ns_500000_nc_100000_contigs 100000 28002479279 10140 280024.8 549926 307966 33074 49 0 ns_50000_nc_5000_contigs 5000 402606570 11391 80521.3 149534 86780 1894 49 0 ns_500_nc_5000_HIGH_INSERTION_RATE_contigs 5000 400779688 11241 80155.9 149479 86447 1890 49.01 0 ns_75000_nc_5000_contigs 5000 401074812 10244 80215 149609 87005 1893 49 0

#### Real datasets {#sec-real-data}

To evaluate tool performance in real-world scenarios, we used predicted viral contigs and CRISPR spacers from recent comprehensive databases.

**Viral contigs:** We used the IMG/VR4 v1.1 high-confidence viral contigs [@camargo_img_vr4_2023], one of the most comprehensive databases of uncultured phage and viral genomes. These sequences are predicted primarily via geNomad [@camargo_genomad_2024] scans of metagenomic data, supplemented with sequences from NCBI's RefSeq and GenBank databases.

To focus on prokaryotic phages and exclude eukaryotic viruses (which typically lack CRISPR systems in their hosts), we applied taxonomic filtering based on ICTV classifications. Specifically, we removed contigs classified into eukaryotic virus families, orders, and classes, including but not limited to major groups such as Adenoviridae, Herpesviridae, Poxviridae, Coronaviridae (families); Herpesvirales, Picornavirales, Bunyavirales (orders); and Megaviricetes, Alsuviricetes, Pokkesviricetes (classes). We additionally filtered out contigs ≤1000 bp to ensure sufficient sequence length for reliable spacer-protospacer matching. After these filtering steps (starting from 5,457,198 high-confidence contigs), the final dataset contains 5,115,894 prokaryotic viral contigs with a total size of \~79 Gbp (range: 1,001 - 2,473,870 bp, median: 7,664 bp, GC%: 44.45%). See Supplementary Table S2 for detailed statistics on the contig dataset and filtering steps.

For benchmarking, we selected a high-quality (HQ) subset of 421,431 contigs (\~18.9 Gbp) using stratified sampling to maintain taxonomic class label distributions while focusing on the most reliable viral sequences. This HQ subset served as the base set for subsampling experiments and derived performance analyses. This set is available in the Zenodo deposit of this project [@zenodo_doi].

**CRISPR spacers:** We used the curated spacer dataset from iPHoP (June 2025 release) [@Roux2023_iphop], which combines CRISPR spacers from both reference genomes and metagenomes. To our knowledge, this dataset represents the largest curated spacers extracted from assembled data and is used in existing host-prediction tools. The raw iPHoP set contain 3,882,812 unique spacers (length range: 25-40 bp, median: 34 bp, GC%: 47.6%) compiled from CRISPR arrays identified primarily via piler-cr [@edgar_piler_cr_2007] and CRT [@bland_crt_2007]. We applied minor additional filtering to remove 55833 spacers (\~1.4% of all) with low sequence complexity or ambiguity (see below "Complexity filtering"). The entire final set of 3,826,979 spacers was used in all benchmarking analyses pertaining to the "real data". See Supplementary Table S3 and Supplementary Figure S7 for detailed statistics on the spacer dataset composition and feature distribution.

**Complexity filtering:** In this work, our goal is to benchmark the different tools results when they are executed with the most suitable parameters and settings (often CLI arguments) for the task of spacer-protospacer matching. From that perspective, investigating the effects of different complexity filtering algorithms and implementation is outside the scope of this project. The different tools evaluated handle complexity and ambiguity differently - some have internal, hard-coded restrictions (e.g. blastn does not select seeds from regions with ambiguous (`N`) bases, but allows extending over them from another seed), or provide option to disable complexity filtering (such as `-dust no` CLI option in blastn). Some tools (like sassy) may allow all query sequences to contain Ns, but may allow restricting the target sequence to region with a maximal fraction of N positions. Previous uses of blastn for this task (such as in CRISPRTarget) tend to explicitly disable complexity filtering. Some host-assignment tools (such as iPHoP) employ complexity filtering post-hoc (after collecting the search/alignment tool results). To provide a uniform starting position for all tools, so that the complexity handling is not a confounding factor, we applied a basic complexity filter to remove spacers with low sequence complexity or high ambiguity. We note that these sequences are likely not particularly informative from a biological perspective and may arise from incorrect CRISPR array prediction or extraction, and in some in-house tests for this project, we observed these disproportionately contribute to the computational resource issues associated with a non-informative matches (such as extremely massive output files detailing "potential" alignments to regions of Ns).\
The steps and code to reproduce the filtering are available in the project repository (spacer_inspection.ipynb). Briefly, we first calculated the fraction of each nucleotide (A, T, G, C, N) in each spacer sequence, as well as the GC%, Shannon entropy value, and the number of non-unique 6-mers (i.e., 6-mers that occur more than once in the spacer). We then filtered out spacers with any of the following characteristics: any ambiguous bases (N fraction \> 0), low sequence complexity (Shannon entropy ≤ 1), high homopolymer content (any of A, T, G, C fraction ≥ 0.95), or low k-mer diversity (≥4 non-unique 6-mers). This filtering removed 55,833 spacers (\~1.4% of all) and resulted in a final set of 3,826,979 spacers used in all benchmarking analyses pertaining to the "real data".

**Stratified Subsampling Strategy:** For benchmarking purposes, we selected an initial high-quality (HQ), representative subset of 421,431 contigs from the raw IMG/VR4 dataset as described above, termed "fraction_1". In this benchmark, we measure the tool results on subsamples of this set for three reasons: first, we can only include the exhaustive tools (Sassy, indelfree.sh bruteforce) on the smaller fraction as they are computioanlly expensive, secondly by comparing the fraction to fraction variation in each tool's result, we can estimate the tools performance consistency, and thirdly, we can investigate the effect of the dataset (fraction) size on the tools' resource usage (CPU time, memory). To create these subsamples, we employed a "Representative Sampling" aimed at ensuring the samples reflect the entire sequence population characteristics and diversity. Specifically, each sampled subset had to include representatives from each taxonomic class, at the same proportional quantities the classes had in the 421k contig set. We note that this is a crucial step as the majority of the prokaryotic viruses in IMG/VR4 belong to a handful of classes causing random sampling with small sizes to have few or no representative for the various other viral lineages. Using the stratified sampling method, we created subsets of several different fractions: 0.0005 (279 contigs, 7.04 Mbp), 0.001 (421 contigs, 9.75 Mbp), 0.005 (2,107 contigs, 57.06 Mbp), 0.01 (4,214 contigs, 123.67 Mbp), 0.05 (21,071 contigs, 715.07 Mbp), 0.1 (42,143 contigs, 1.50 Gbp), and 1.0 (full HQ set: 421,431 contigs, 18.87 Gbp). The same set of 3,826,979 spacers was used for all subsamples and the full HQ set. Note that even for the smaller subsamples (0.0005-0.01 fractions), not exhaustive tool completed within reasonable CPU time budgets. Note, in this project, we only include the alignments reported by any tool if that tool finished within the same time limit. A singular exception is blastn for the fraction_1 set, which was allowed to run completion, as it the main point of reference with regards to historical use of (any) tool for this task.

#### Synthetic dataset generation {#sec-synthetic-data}

To examine each tool's performance across diverse spacer-to-target matching scenarios, we developed a Rust-based simulation framework accessible through a Python CLI interface with fine-grained control over sequence characteristics. The simulator records the ground truth of all planned spacer occurrences, enabling differentiation between true positives (planned matches) and non-planned matches (validated alignments occurring in unplanned regions but meeting distance thresholds).

**Customizable Sequence Characteristics:** The simulation framework provides several parameters to enable more realistic sequences. Users can specify nucleotide base composition independently for spacers and contigs through either GC content percentages or explicit base frequency parameters (A, T, C, G fractions). Additional parameters control contig and spacer length distributions (uniform or normal), the range of substitution mismatches to introduce when injecting a spacer into simulated contigs, the number or range of times each spacer would be "injected" into a simulated contigs, optional indel mutations (insertion and deletion ranges), and the proportion of spacers to reverse complement. Additionally, a semi-synthetic option is permitted - where either an external (existing) spacer or/and contig set is read from file.

**Sequence Generation Process:** The Rust-based core of the simulator generates DNA sequences using weighted random sampling from the nucleotide alphabet (A, T, C, G) based on the specified base composition. For each position in a sequence, a nucleotide is selected with probability proportional to its configured frequency. Sequence lengths are sampled from the specified distribution type: uniform distributions select lengths with equal probability across the range; normal distributions sample from a Gaussian with mean at the midpoint and standard deviation chosen to span the range; and bell curve distributions use a Beta distribution to create length variation with mode near the center. Before actual sequence modifications begin, the simulator creates an "injection" plan ("injection" refers to replacing a contiguous region of a contig with a spacer sequence, creating what we refer to as "planned spacer occurrences" - this should not be confused with "insertion" indel mutations, which add bases within sequences). This plan predetermines which spacers will be placed into which contigs, how many times each spacer appears, which occurrences will be reverse-complemented, and what mutations each will receive. The plans is then executed across seperate processing threads, so that the load (number of spacers and to generate contigs) is balanced by by total spacer-placement lengths so that a similar value is assigned to each thread. To prevent individual contigs from becoming overly saturated with spacers, the simulator calculates contig utilization - the percentage of total contig base pairs that will be occupied by injected spacers - and reports this value (note - in the simulation run describied below this value remained mostly below 2%). During injection, each spacer replaces an existing contig region of equal length at a randomly selected position, thereby preserving the original contig length while creating the "ground truth" alignments. When injecting spacers into these predetermined positions, the simulator applies mutations in a defined order: first, indels (insertions and deletions) mutations are applied seperatly at random positions (note - this option was not used in the current project); second, substitutions ("mismatches") replace bases with different nucleotides (preventing identity-preserving substitutions like A→A) at random positions. The number of substitions, the injected spacer coordiantes on the contig, the strand, and the contig and spacer identfiers are recorded as the (planned) ground truth. The final outputs the contigs and spacer seqeuences (as FASTA files), and the ground truth (in tabular format).

**Comparison to real spacers:** Rather than using purely random sequences and uniform distributions, for the sets described here, we configured the synthetic data generation to match certain characteristics of the real-datasets (i.e. the filtered iPHoP spacer set and the HQ IMG/VR4 dataset noted above as "fraction_1"). Specifically, we set the GC content to approximately 49% (spacers), and 46% (contigs), and configured contig lengths to be selected under normal distribution from a realistic range (mostly, 1,501-200,000 bp, see Supplementary Table S4 for complete parameters). To demonstrate the ability of the simulated sequences to mimic the real data sets, we calculated and compared several features (e.g. k-mer repeatability, entropy, base frequencies etc) (see Supplementary Figure S6 and notebooks: spacer_inspection.ipynb). Most analysed features indeed appear similar for the simulated and real sequences, with the exception of that in some complexity measures (k-mer repeatability and LCC), the real spacers have slightly wider range of value, suggesting a minor amount of the real spacers have more extreme values in this regards.

**Simulation Dataset Variants:** We generated multiple synthetic datasets with varying sizes and characteristics to evaluate tool performance under different conditions and to assess the tools consistency (for similar reasons as the real-data subsamples). The datasets follow a naming convention ns\_\[n_spacers\]*nc*\[n_contigs\] indicating spacer and contig counts. Smaller datasets (ns_50000_nc_5000, ns_75000_nc_5000, ns_75000_nc_10000) used 25-40 bp spacers, 10,000-150,000 bp contigs under normal distribution, 1-5 spacer insertions (placements, injections) per each simulated spacer, and 0-5 substitution mismatches, with all tools evaluated at hamming distance ≤5. Medium-sized datasets (ns_100000_nc_10000, ns_100000_nc_20000) used similar parameters with all tools at hamming distance ≤5, while the largest dataset (ns_500000_nc_100000 with 500k spacers and 100k contigs spanning 10,000-550,000 bp) was limited to hamming distance ≤3 and excluded exhaustive tools (Sassy, indelfree bruteforce) due to computational constraints. Additionally, we created a specialized high-insertion-rate dataset (ns_500_nc_5000_HIGH_INSERTION_RATE) with only 500 spacers but 100-2,500 injections per simulated spacer to test tool behavior under extreme multi-mapping scenarios, and a minimal dataset (ns_100_nc_50000) with 100 spacers across 50,000 contigs (2,500-850,000 bp range, 1-3 injections, 25-45 bp spacers) for rapid validation. All synthetic datasets configured spacers and contigs with GC content matching real data (49% and 46% respectively), used normal length distributions, and included 50% reverse-complemented injections to reflect biological reality. See Supplementary Table S4 for complete simulation parameters and resulting dataset statistics. Note, not all tools were able to complete all runs within the same time limit for all subsamples (see "Computational Resource and Runtime Tracking" for details).

#### Semi-Synthetic dataset

This set uses the existing simulation framework, but instead of generating both spacers and contigs from random sequences, we use the same filtered spacer set as the real-datasets, and generate synthetic contigs matching the sequence characteristics of the HQ IMG/VR4 dataset (fraction_1, see Supplementary Table S2 for dataset details). Note, the spacers are not "injected" into the simulated contigs (using the `--number-spacer-insertions 0 0` option of the `simulate` command). Wr primarily use this set to estimate "non-planned" match rates in a realistic spacer set sequence composition context, and realistic search space context. In this context (0 planned spacer occurrences) we expect all identified matches to reflect chance similarity. We note that this set is considered "large" (by design, similarly to the fraction_1), hence we are only able to use an aggregate of the verified non-exhaustive tools, and only under hamming distance ≤3. This suggests that the actual count and rate may actually be larger. See the "Non-planned Match Rate Estimation" section below for details on the definition of "non-planned" matches.

### Coordinate Tolerance and Unique Region Counting {#sec-coordinate-tolerance}

When aggregating results across tools, we implement coordinate tolerance matching to handle slight boundary differences in reported alignments. We observed tools may report alignments with minor variations in start/end coordinates (typically 1-5 bp) due to different handling of terminal mismatches or gaps (see Supplementary Note 1 for detailed example). We use a default 5bp tolerance when merging alignments to count unique spacer-contig regions. This approach reduces double-counting of essentially identical matches, accounts for valid algorithmic differences in gap versus substitution placement at alignment boundaries (or variation in tool-specific "clipping" behavior), which enables fair comparison of tool results coverage (total unique regions detected). All reported alignments from all such regions are verified separably, by extracting the reference contig region and realigning to the spacer sequence (see Alignment Verification section below).

### Alignment Verification and Distance Metric Calculation {#sec-alignment-recalc}

For comparing alignments across tools, we use hamming distance (counting only substitutions) as our primary distance metric, with biological and computational justification provided below. Our benchmarking CLI tool supports setting thresholds for three distance metrics: (minimal) hamming distance, (minimal) edit distance, and gap-affine (by measuring the edit distance from an alignment with a user provided cost matrix and gap penalties). However, for the analyses presented here, we focus primarily on hamming distance ≤3 for most datasets, with hamming distance ≤5 used in datasets where computational resources permitted. As noted in the introduction, we recommend prioritizing hamming distance for spacer-protospacer matching in the context of phage-host interactions, as this better reflects the predominant mutation types observed in experimental studies of phage escape from CRISPR immunity. To clarify, in the context of gene-editing, a minimal edit distance might serve as a more appropriate metric for off-target prediction. Despite this recommendation, we have attempted to compare hamming and edit distance effects empirically in our analyses (when computationally feasible). We note that while in practice, we observed near complete agreement between the minimal edit and gap-affine distance metrics under the conditions tested, these are not identical measurements - a gap-affine distance metric allows for more flexible gap placement and scoring, aimed at capturing biologically relevant (i.e. sharing a common ancestor) relationships, while the minimal edit distance metric will prioritise the minimal set of edits (substitutions and indels) regardless of their evolutionary likelihood (e.g. the higher rarity of indels compared to substitutions).

**Distance Verification Methodology:** To ensure consistent and accurate distance calculation across tools that use different internal alignment algorithms and scoring schemes, we independently recalculated distances for all reported alignments post-hoc. For the gap-affine distance metric, parasail's [@Daily2016_parasail] implementation of the Needleman-Wunsch global alignment algorithm is used, for the minimal edit distance metric, the python version of the edlib library [@Šošić_Šikić_2017_edlib] is used (`edlib.align`). For the hamming distance metric, we measure the number of non-identical residues in the aligned region. As hamming distance can only be calculated for alignments of the same length, and as some tools report gapped alignments, we first pad the shorter sequence with non-matching characters (e.g. "\@") and then calculate the hamming distance as the count of positions where the two sequences differ. This approach also address potential difference in clipping behavior between tools.

### Performance definitions and calculation {#sec-performance-calc}

We defined the ground truth and classified alignments slightly differently for synthetic and real datasets, as for the larger real-data sets we do not have the results of an exhaustive tool to establish a complete set of alignment.

Speficially, for synthetic datasets, we define three categories: 1. **positive_in_plan:** Alignments matching planned spacer occurrence coordinates (±5bp tolerance, see §sec-coordinate-tolerance). These represent the intended ground truth matches, i.e. sequences were generated following the simulation pre-planned design at known coordinates, strands, and number of mismatches. 2. **positive_not_in_plan:** Tool reported alignments within the allowed distance threshold passing our independent validation, but occurring outside planned regions. These represent chance similarities at the specified distance - not false positives in the technical sense (they are valid alignments), but non-planned matches that may indicate increased background noise under a certain condition (distance threshold, search space size, see the "Non-planned Match Rate Estimation" section below). 3. **invalid_alignment:** Alignments that fail the independent alignment verification, or exceed quality thresholds. These are "true" (in the classical sense) false positives, and we note these tend to result from tool-specific reporting artifacts - not all tools support limiting reported alignments within a specific distance metric and threshold (e.g. strobealign do not have any explicitly option to control what alignments are reported), and the parameters we provide to these tools can only approximate it (such as minimal identity or minimal query coverage). Note that the parameter choice is aiming to include at-least all matches within our analysis scope (hamming ≤3) but often includes a larger range. In the context of this project, we discard these "invalid-alignments" and do not investigate them further.

We extend these definitions to the real datasets by treating all (validated) alignments reported by all tools as "positive_not_in_plan".\
In this project, we define a tool's "Recall" as the positive rate, or fraction of positives detected by tool. When this fraction is calculated out of the planned alignments only (not including the non-planned), we specify it by noting "non augmented" (e.g. "non-augmented recall"). This reflects our choice to consider the non-planned validated matches as positives. We argue that from a pure sequence alignment perspective, they are as correct (within the distance threshold) as the planned, and that for the real datasets, where we do not have a complete set of planned matches, this is the only way to calculate recall in practice. Furthermore, we specifically recommened the distance metric and threshold choice (hamming≤3) as we estimate to by considerably low than the number of real alignments we observe in the real data-set (note, this is not the case for higher distance thresholds or for differnet distance metrics). Additionally, we note that metrics such as precision ((\frac{TruePositives}{TruePositives+FalsePositives})) are not applicable in this context - as were we to define the non-planned matches as false positives (for the synthetic sets),we could control this value by adjusting the simulation parameters (i.e. the number of planned spacer occurrences). We also note that in this framework "true negatives" ("all correctly not reported matches that do not actually align") is not a sensical or useful defintion. By extension we can not compute certain common performance metrics such as specificity.

We acknowledge that a limitation of this system is the lack of a complete set of all positives for datasets too large to be exhaustively searched (using sassy and indelfree.sh bruteforce mode). In such cases, the positive set is essentially the union of all valid tool reported alignments.

**Non-planned Match Rate Estimation:** Using the synthetic datasets allows us to estimate the frequency of these reported alignments as a dependency of distance metric and threshold, and of the search space size. As we control the exact details in the simualted runs, we generate a ground truth table, where the location, number of mismatches, spacer and contig identifiers of each planned spacer occurence is recorded. By combining this ground truth with the different tool results (particularly the exhaustive ones), we are able to identify (and subsequently verify) any reported alignment - and record the number of valid (within distance threshold) alignment not explictly planned (occurring in regions other than those in the simulation plan). We expect these non-planned matches to represent chance similarities arising from sequence composition and length. To estimate the rate of such non-planned matches, under a given distance threshold, we divide the number of validated non-planned matches by different representations of the total search space size: A metric "engulfing" both spacer and contig set sizes in pp (sum of spacer legnths \* sum of contig lengths), or the product of the number of spacers and contigs (e.g. per n spacer and m contigs). Realistically, total spacer length is negligible compared to total contig length, however the product of the number of spacers and contigs assumes every contig and spacer effect the search space equally.\
We quantified non-planned match rates using the exhaustive search tools under varying hamming (indelfree bruteforce) and edit (sassy) distance thresholds (1 - 5). For large datasets (where the use of exhaustive search tools is too computationally prohibitive), we either reduced the threshold the range (1-3) if possible, although for the full set (fraction_1, the semi-synthetic set, and the largest of the simulated runs) we resorted to use the aggregation of the non exhaustive tools (namely Bowtie1 and blastn) results as proxy. Complete analysis and methodology details are provided in Supplementary Note 3.

%%%%% maybe move this to results %%%%% This methodology revealed that non-planned match rates increase dramatically with allowed distance, with substantially higher rates when allowing indels compared to substitutions only. At hamming distance \u22643, we observed 54,388 non-planned matches (approximately 0.36 per million spacer-bp × million contig-bp) in the semi-synthetic set. The non-planned match count decreased to 2,217 at hamming distance \u22642, 47 at hamming distance \u22641, and only 1 exact non-planned match at hamming distance = 0. For this rate under edit distance, the computational requirement of the exhaustive tools restricted the analysis to the smaller simulated datasets only. Complete results, including per-distance breakdowns, validation analyses, and detailed comparison tables, are provided in Supplementary Note 3 and the distance_metric_analysis notebook in the project repository. %%%%% maybe move this to results %%%%%

### Benchmarking framework {#sec-benchmark}

### Computational Resource and Runtime Tracking {#sec-resource-tracking}

While the primary focus of this study was to evaluate the ability of each tool to accurately identify spacer-protospacer matches, computational resource usage are a limiting factor for certain dataset sizes. This is particularly relevant for the exhaustive tools (Sassy and indelfree.sh in bruteforce mode), which have high computational costs.

The CLI benchmarking tool we developed utilises hyperfine [@Peter_hyperfine_2023] for local execution of tools (suitable for smaller datasets), and a SLURM (Simple Linux Utility for Resource Management [@SLURM_2002]) based method (suitable for larger datasets ran on high-performance-compute clusters), where we captured the resource usage via SLURM's built-in accounting system (`sacct`), accessed through a custom Python wrapper. For consistency, all analyses herein were performed using the SLURM tracking approach. Both approaches allow us to capture detailed resource usage metrics, including wall clock time, CPU time, and peak memory usage, which are critical for understanding the practical feasibility of each tool under different conditions. All SLURM job logs were retained for reproducibility and are available in the Zenodo repository. All tools were allocated the same CPU and memory resources (64 threads, 512 GB RAM) to ensure a fair comparison, and the same maximum wall time limit (72 hours) was applied to all runs. If a tool exceeded the wall time limit, it was terminated and marked as "timed out" for that dataset, and no results were recorded for that run. The only exception to this was blastn for the fraction_1 set, which was allowed to run to completion as it is the main point of reference with regards to historical use of (any) tool for this task.\
We note that memory (RAM) tracking for some java tools (particularly BBMap suite tools such as indelfree.sh) can seem to use all available memory as the java virtual machine may not explicitly report cleared, unused memory, in a way visible to the SLURM accounting system. This means that the SLURM reported peak memory usage may not indicate the actual minimal requirement of a tool. For tools that require generating an index file (or any additional obligatory steps and commands) prior the actual search/scan/alignment command, we include the index construction time (or the additional commands) in the total runtime of a tool as these represents real computational cost, though for production use with repeated searches, index construction might constitute a one-time cost.

### Versioning and Reproducibility {#sec-reproducibility}

Versioning and Reproducibility {#sec-reproducibility}All tools were installed and managed using conda [@conda] (via the mamba [@mamba] package manager) in isolated environments. To prevent dependency conflicts and ensure reproducibility, most tools were installed in dedicated environments. Environment activation time was excluded from performance measurements to focus on actual tool runtime. The exact versions and configurations of all tools were recorded in environment files, allowing for exact replication of our testing environment.All benchmarks were performed on a standardized high-performance computing node to ensure consistency. The hardware environment consisted of a dual-socket system equipped with two AMD EPYC 7543 32-Core Processors, providing a total of 64 physical cores and 64 threads. The CPUs operated at a frequency of 3705.616 MHz with a 32 MB L3 cache. The system was equipped with 512 GB of RAM ($5.5 \times 10^{11}$ bytes) and utilized a SAMSUNG MZ1LB1T9HALS-00007 storage unit managed via an NFS filesystem.The software stack was deployed on Linux (kernel version 4.18.0-553.58.1.el8_10.x86_64) using an x86_64 architecture. Benchmarking scripts were executed using Python 3.10.19.

### Extensibility

The framework is designed to be expandable through the integration of new tools. Each tool/software configuration is saved as a separate JSON file, which includes the exact commands and conda/mamba environment it uses. This configuration files can use placeholder variables which the main benchmarking software replaces (according to the users' CLI arguments) during execution (such as `{threads}`, `{contigs_file}`, `{spacers_file}`, `{output_dir}`, and `{results_dir}`). A new JSON file can be added manually or via bench.utils.tool_commands:add_tool function in a semi automated method.

## Results

### Selection of distance metric and threshold values {#sec-distance-metric-selection}

We selected hamming distance ≤3 as our primary distance metric and threshold for the main analyses, based on empirical measurement of non-planned match rates combined with biological and computational considerations. To investigate the effects of metric and threshold choice, we utilized both simulated and semi-synthetic datasets to quantify non-planned match rates. As noted in the methods (see Methods §sec-performance-calc), these non-planned matches are not considered "false positives" in the traditional sense, as they represent valid alignments within the distance threshold (verified independently of which tool reported them) that occur in regions not explicitly included in the simulation plan. In this section, we use these non-planned matches to estimate the expected "background noise" under different distance metrics (edit versus hamming), thresholds (exact distance or cumulative up to a distance), and search space sizes (based on simulation/dataset parameters).

The semi-synthetic dataset, combining 3,826,979 real spacers with 400,000 synthetic contigs totaling approximately 18.9 Gbp, provided the most realistic assessment of non-planned match frequency. Using exhaustive search tools on smaller subsamples and validated heuristic tool aggregates on the full dataset, we observed systematic increases in non-planned matches with increasing distance threshold. At hamming distance 0, only 1 exact non-planned match was identified across the entire search space. This increased to 47 matches at hamming distance ≤1, 2,217 matches at hamming distance ≤2, and 54,388 matches at hamming distance ≤3. Normalizing by search space size, this corresponds to approximately 0.36 non-planned matches per million spacer-bp searched against million contig-bp at hamming distance ≤3.

For edit distance thresholds, computational constraints limited exhaustive analysis to smaller simulated datasets. Using Sassy on synthetic datasets, we observed substantially higher non-planned match rates when allowing indels. At edit distance ≤3, non-planned match frequencies exceeded hamming distance ≤3 rates by approximately 5-10 fold depending on dataset composition. Complete methodology and detailed results are provided in Supplementary Note 3 and the distance_metric_analysis notebook.

Based on these empirical measurements combined with biological evidence for substitution-dominant mutation patterns in phage escape, we selected hamming distance ≤3 as the primary threshold for subsequent analyses. This threshold maintains low non-planned match rates while capturing biologically relevant sequence divergence. We acknowledge that for certain specific research questions and scenarios, an edit distance may be more appropriate, see supplementary nnn for detailed values for the edit distance analysis.

\<???some figures???\>

### Tool performance across mismatch thresholds {#sec-mismatch-performance}

![Tool recall (detection fraction) as a function of hamming distance threshold. Panel A shows performance on simulated data with known ground truth, while Panel B shows performance on IMG/VR4 real data. The horizontal axis indicates hamming distance threshold (0-3 substitutions allowed), and the vertical axis represents recall (fraction of valid aligned regions detected, 0-1). Each line represents a different tool, with shapes indicating data points. Note: For real data, recall is calculated against the aggregate of all tool-detected regions rather than absolute ground truth. See Supplementary Figure S3 for simulated dataset performance, Supplementary Table S5 for complete recall values.](figures/main/tool_performance_by_mismatches.svg){#fig-tool-performance}

Tool performance varied systematically with hamming distance threshold (@fig-tool-performance). At hamming distance 0 (exact matches), multiple tools achieved recall exceeding 0.99 on both simulated and real datasets, including Bowtie1, Bowtie2, BLASTn, and MUMmer4. However, no single tool identified all spacer occurrences even at this most restrictive threshold. As mismatch tolerance increased, performance divergences between tools became more pronounced.

At hamming distance ≤1, most tools maintained recall above 0.90, with Bowtie1 achieving the highest recall at approximately 0.98 on both datasets. At hamming distance ≤2, performance gaps widened further, with Bowtie1 maintaining recall above 0.96 while other tools ranged from 0.70-0.92. At the primary analysis threshold of hamming distance ≤3, Bowtie1 sustained recall above 0.95 on both real and simulated datasets, while other heuristic tools showed more substantial decreases. StrobeAlign and Minimap2 exhibited the steepest performance declines with increasing mismatches, likely reflecting design optimizations for their primary use case of long-read mapping rather than short, highly divergent sequence matching.

Performance patterns were consistent between simulated and real datasets, though the smaller simulated dataset size and availability of exhaustive tools on synthetic data enabled more precise recall measurement. Complete per-tool, per-threshold recall values are provided in Supplementary Table S5.

### Performance as a function of query (spacer) abundance in reference database {#sec-abundance-performance}

![Comparison of recall (detection rate) across different mismatch thresholds and target abundance levels for IMG/VR v4 virus and spacer dataset. Top panel displays the subset of results with up to 1 mismatch, and the bottom panel displays the results with up to 3 mismatches. The horizontal axis shows the number of target occurrences on a logarithmic scale from 1 to 10^4^, while the vertical axis represents the mean detection fraction (0-1). Each color and shape indicates a different tool plot (shapes connected by lines for interpolation). The low-abundance region (1 - 1000 occurrences) is binned into logarithmically-spaced bins, while the high-abundance region (\>1000 occurrences) is divided into only 3 additional bins, as such ultra-high abundance sequences are rare. The detection fraction is the mean detection fraction across all spacer-contig pairs at a given mismatch threshold and target abundance level.](figures/main/recall_vs_occurrences_combined.svg){#fig-recall}

We then investigated if there are any potential effects for the number of times each protospacer sequence appears in the target set (i.e. the virus sequence set). For perfect matches (0 mismatches), bowtie1 demonstrates exceptional performance with recall rates consistently above 0.99 across all occurrence frequencies (Figure 2). Mummer4, bowtie2 and blastn all maintain a detection rate close to bowtie1. For low-occurrence spacers (1-10 occurrences), strobealign achieves detection rates of 95.44% but shows a systematic decline to approximately 20% for spacers occurring \>100 times, and further drops below 5% in the high occurrence range (\>1000).

When allowing one mismatch, the overall detection capabilities decrease across all tools, although Bowtie1 maintains its high performance. At up to three mismatches, the overall recall rates for all other tools further decrease, while Bowtie1 maintains detection rates above 97% throughout the occurrence spectrum.

The data shows a consistent pattern where detection rates generally decline for spacers with very high occurrence frequencies (\>1000), though this effect becomes less pronounced as more mismatches are permitted. Quantitatively, this decline is most evident in tools like strobealign, while bowtie1 maintains its high performance even with highly repetitive sequences. Detailed statistics and recall curves for exact mismatch values (rather than at a maximal value) can be found in the supplementary.

### Pairwise tool comparison and unique detections {#sec-pairwise}

![Tool-versus-tool comparison matrices showing unique alignments detected by one tool but not another at hamming distance ≤3. Cell (i,j) represents the number of unique spacer-contig alignment regions identified by tool i (row) but not by tool j (column). Panel A: Simulated dataset with ground truth. Panel B: IMG/VR4 real dataset. Darker colors indicate more unique detections. See Supplementary Figure S2 for per-mismatch threshold matrices (exact hamming distances 0, 1, 2, 3).](figures/main/tool_comaprison_matrix.svg){#fig-pairwise}

Pairwise tool comparison matrices reveal the extent of unique detections between tools (@fig-pairwise). Bowtie1 consistently identified the largest fraction of alignment regions across both datasets, with relatively few regions uniquely detected by other tools that Bowtie1 missed. Conversely, Bowtie1 identified substantial numbers of regions not found by individual other tools. For example, on the IMG/VR4 dataset at hamming distance ≤3, Bowtie1 detected approximately 50,000-150,000 more unique regions than each of the other top-performing tools (BLASTn, Bowtie2, MUM mer4), while missing fewer than 5,000-20,000 regions that those tools uniquely identified.

The asymmetry in these matrices underscores tool-specific sensitivity limitations. Tools employing more restrictive heuristics (StrobeAlign, Minimap2, MMseqs2) showed larger numbers of regions uniquely detected by other tools, reflecting their optimization for different primary applications. BLASTn showed relatively balanced performance compared to other tools, though still detecting fewer total regions than Bowtie1.

For the simulated dataset, where ground truth is available, we confirmed that regions uniquely detected by non-Bowtie1 tools predominantly represented true planned occurrences rather than false positives, validating that no single tool achieves perfect recall. The aggregation of all tools provides the most complete alignment catalog, particularly when including exhaustive search results where computationally feasible. Upset plots showing complete set intersections across all tools are provided in Supplementary Figure S8, revealing complex patterns of tool agreement and disagreement beyond pairwise comparisons.

### Computational Resource Requirements and Scalability {#sec-resource-usage}

Computational resource requirements vary dramatically across tools, reflecting fundamental differences in algorithmic approaches and trade-offs between sensitivity and efficiency (@fig-resource-usage). Understanding these resource requirements is essential for practical tool selection, particularly as CRISPR spacer and viral databases continue growing rapidly.

![Computational resource usage across tools on synthetic and real datasets. Panel A shows wall clock time vs dataset size for IMG/VR4 subsamples, demonstrating scaling behavior. Panel B shows peak memory usage vs CPU time for simulated datasets, with point size indicating total search space. Panel C shows CPU time scaling with search space size (spacer-bp × contig-bp). Exhaustive tools (Sassy, indelfree bruteforce) shown in red/orange hues; heuristic tools in blue/green hues. Note: Resource tracking for BLASTn on fraction_1 extrapolated from partial completion (1.69M of 3.83M spacers processed within 72h time limit). See Supplementary Note X for complete resource usage tables and scaling analysis.](./figures/main/resource_usage_simulated.svg){#fig-resource-usage}

Tool runtime and memory requirements span several orders of magnitude. On the full IMG/VR4 HQ dataset (3,826,979 spacers × 421,431 contigs, 18.9 Gbp), Bowtie1 completed searches in approximately 12-36 hours wall time using 64 threads, consuming peak memory of 8-12 GB. In contrast, exhaustive tools proved computationally prohibitive at this scale. Sassy on the 5% IMG/VR4 subsample (21,071 contigs, 715 Mbp) required approximately 1 million CPU-seconds. Extrapolating linearly to the full dataset would require greater than 20 million CPU-seconds (approximately 230 CPU-years), rendering it impractical for routine analysis.

Heuristic tools demonstrated varying resource requirements. Bowtie2 and StrobeAlign showed similar efficiency to Bowtie1, completing full-dataset searches within 24-48 hours with peak memory under 20 GB. MMseqs2 required substantially higher memory (100-200 GB) but completed searches in comparable wall time when sufficient memory was available. BLASTn exhibited intermediate performance, though parameter sensitivity significantly affected runtime. On the full IMG/VR4 dataset with our sensitivity-optimized parameters (low word size, high `max_target_seqs`), BLASTn exceeded the 72-hour walltime limit after processing 1,689,771 of 3,826,979 spacers. Extrapolating from observed runtime suggests completion would require approximately 150-180 hours, though actual completion time may vary due to non-linear scaling with occurrence frequency.

Scaling behavior differed markedly across tools. Analysis of multiple IMG/VR4 subsamples (fractions 0.001 to 1.0, spanning 421 contigs/10 Mbp to 421,431 contigs/18.9 Gbp) revealed distinct scaling patterns. Bowtie1, Bowtie2, and StrobeAlign exhibited near-linear scaling with dataset size, with runtime approximately proportional to total sequence length. MMseqs2 and MUMmer4 showed slightly superlinear scaling, likely reflecting k-mer index size effects. BLASTn demonstrated highly variable scaling depending on occurrence frequency distribution, with runtime disproportionately affected by high-abundance spacers due to reporting all valid alignments up to `max_target_seqs` threshold.

Memory requirements also varied substantially. Index-based tools (Bowtie1, Bowtie2, StrobeAlign, MUMmer4) required modest memory (5-30 GB) after index construction. MMseqs2 demonstrated the highest memory demands (100-300 GB depending on dataset), while Sassy peak memory scaled with dataset size, ranging from 20 GB on small synthetic datasets to projected requirements exceeding 500 GB for IMG/VR4-scale data. Tools from the BBMap suite (indelfree.sh) present special considerations, as Java-based memory management may report higher peak usage than actual minimal requirements.

For indexed tools, index construction represents a one-time upfront cost. Bowtie1 index construction for the full IMG/VR4 HQ dataset required approximately 4-6 hours and 20 GB peak memory. While substantial, this cost avoids repeated index building for multiple searches, making indexed approaches favorable for repeated queries against stable reference databases.

These computational requirements have direct implications for research feasibility. As spacer databases continue expansion (from 366,799 in 2017 to 3,826,979 in 2023, ref), and viral metagenomes grow similarly, tool choice increasingly constrains analytical possibilities. Exhaustive tools, despite guaranteeing perfect recall, remain limited to validation roles on small subsamples. Heuristic tools with efficient scaling properties (particularly Bowtie1) enable comprehensive analysis at current database scales and provide the only practical path forward as datasets continue growing. Complete resource usage tables, scaling analyses, and per-fraction performance metrics are provided in Supplementary Table SX and the Resource_usage notebook

2.  **Bowtie1 offers optimal balance:** Combining high recall (\>95% for ≤3 mismatches), low non-planned match rates at hamming distance ≤3, and excellent computational efficiency, making it the practical choice for most applications.

3.  **Exhaustive tools for validation:** Tools like Sassy and indelfree.sh bruteforce mode are valuable for establishing baseline performance on small subsamples and validating heuristic tool results, but not for production workflows.

These computational considerations reinforce our recommendation of Bowtie1 for most applications, with exhaustive tools reserved for specialized validation studies or small-scale analyses where their computational costs are acceptable.

## Discussion

### Tool Performance and Recommendations

Our analysis, combining synthetic datasets with known ground truth and real-world metagenomic data, reveals critical insights for CRISPR spacer-protospacer matching tool selection.

**Primary Finding - Hamming Distance vs Edit Distance Analysis:**

Our systematic comparison of hamming distance (substitutions only) versus edit distance (allowing indels) reveals profound implications for match specificity and biological relevance. Using both synthetic datasets with complete ground truth and semi-synthetic datasets combining real spacers with synthetic contigs, we quantified how distance metric choice affects non-planned match rates.

**Distance Metric Selection and Non-Planned Match Rates:**

Our empirical measurement of non-planned match rates (@sec-distance-metric-selection) provides quantitative support for hamming distance ≤3 as an appropriate threshold for most applications. The semi-synthetic dataset analysis revealed that at hamming distance ≤3, only 0.36 non-planned matches occur per million spacer-bp searched against million contig-bp. This low rate, combined with biological evidence for substitution-dominant escape mutations, strongly supports hamming distance for natural spacer-protospacer matching.

Conversely, edit distance thresholds, while appropriate for certain specialized applications (gene editing off-target effects, low-accuracy sequencing data), introduce substantially elevated non-planned match rates. Using Sassy on synthetic datasets, we observed 5-10 fold increases in non-planned matches when allowing indels at edit distance ≤3 compared to hamming distance ≤3. This empirical finding complements biological evidence: indels are approximately 4-fold rarer than substitutions in bacterial genomes, most documented phage escape mutations are single nucleotide substitutions, and phage coding-dense genomes make frameshift-inducing indels particularly deleterious.

The choice between distance metrics represents a fundamental decision about the underlying biological question. For inferring historical phage-host interactions from metagenomic data, where sequence divergence reflects selective pressure on MGEs to mutate and escape host defenses, hamming distance captures the predominant mutation type while minimizing background noise. For applications where indel tolerance is necessary (predicting gene editing off-targets where partial base-pairing including gapped alignments can cause unwanted cleavage, or analyzing Oxford Nanopore R9 or PacBio CLR data where sequencing errors include frequent indels), edit distance metrics become appropriate despite elevated non-planned match rates.

**Tool Selection Flowchart and Recommendations:**

Based on our comprehensive benchmarking, we provide the following evidence-based recommendations organized by use case. @fig-flowchart provides a decision flowchart to guide tool selection based on dataset characteristics and analysis goals.

```{mermaid}
%%| label: fig-flowchart
%%| fig-cap: "Tool selection decision flowchart for CRISPR spacer-protospacer matching. Decision nodes (diamonds) represent classification criteria based on dataset scale, computational resources, distance metric requirements, and biological constraints. Edge labels specify the conditions and reasoning for each path. Terminal nodes (rectangles) indicate recommended tools with performance characteristics and application domains. Bowtie1 (green) represents the primary recommendation for large-scale analyses with hamming distance ≤3. Indelfree.sh indexed (blue) provides extended hamming distance capability (>3 substitutions, up to ≤5). Sassy (orange) enables exhaustive edit distance search for small datasets or low-accuracy long-read data."

flowchart TD
    Start([Tool Selection for<br/>Spacer-Protospacer Matching]) --> Q1{Dataset Scale<br/>and Computational<br/>Resources}
    
    Q1 -->|Small experimental dataset<br/><1M spacers, <10 Gbp contigs<br/>Computational cost acceptable| Q2{Distance Metric<br/>Requirements}
    Q1 -->|Large-scale metagenomic<br/>>1M spacers or >10 Gbp contigs<br/>Efficiency critical| Q3{Distance Threshold<br/>and Biological<br/>Constraints}
    
    Q2 -->|Edit distance needed:<br/>Indel tolerance required for<br/>low-accuracy long reads: ONT R9, PacBio CLR<br/>or mutation type characterization| Sassy[<b>Sassy - Exhaustive Edit Distance</b><br/>✓ Perfect recall, arbitrary thresholds<br/>✓ Supports indels and substitutions<br/>⚠ ~1M CPU-seconds per 5% IMG/VR4<br/>Applications: Experimental phage-host studies,<br/>low-accuracy long-read assemblies,<br/>off-target analysis, methodological validation]
    Q2 -->|Hamming distance sufficient:<br/>Substitutions only<br/>High-quality assembled data: Illumina<br/>Historical infection inference| Q3
    
    Q3 -->|≤3 substitutions:<br/>Biologically relevant threshold<br/>Indels ~4× rarer than substitutions<br/>Most escape mutations ≤3 nt| Bowtie1[<b>Bowtie1 - Hamming ≤3</b><br/>✓ >99% recall at intended threshold<br/>✓ Scales to millions of spacers<br/>✓ Low non-planned match rate<br/>✓ Ungapped alignment only<br/><b>PRIMARY RECOMMENDATION</b><br/>Applications: Large-scale host prediction,<br/>metagenomic spacer-protospacer matching,<br/>high-throughput CRISPR target identification]
    Q3 -->|>3 substitutions:<br/>Extended divergence detection<br/>Accepts higher non-planned matches<br/>Conserved indel-free constraint| Indelfree[<b>Indelfree.sh Indexed - Hamming ≤5</b><br/>✓ Near-perfect recall for hamming ≤5<br/>✓ Maintains substitution-only constraint<br/>⚠ 10-100× slower than Bowtie1<br/>⚠ Higher non-planned match frequency<br/>Applications: Divergent phage detection,<br/>extended mismatch tolerance,<br/>sensitivity-prioritized analyses]
    
    style Bowtie1 fill:#90EE90,stroke:#228B22,stroke-width:3px
    style Sassy fill:#FFE4B5,stroke:#FF8C00,stroke-width:2px
    style Indelfree fill:#ADD8E6,stroke:#4169E1,stroke-width:2px
    style Start fill:#F0F0F0,stroke:#333,stroke-width:2px

```

**Detailed Recommendations by Use Case:**

1.  **Primary recommendation for most applications - Bowtie1 (hamming ≤3):**
    -   **Use for:** Large-scale metagenomic analyses, routine host-virus prediction, high-throughput spacer-protospacer matching
    -   **Performance:** \>95% recall for 0-3 mismatch spacers, \<1% false positive rate
    -   **Advantages:** Excellent computational efficiency, scales well to millions of spacers and billions of bases, maintains high performance even for high-abundance targets
    -   **Limitations:** Maximum 3 substitutions, does not support indels
    -   **Biological justification:** Most experimental escape mutations are ≤3 substitutions; higher thresholds increase false positives without substantial biological gain
2.  **Extended hamming distance - Indelfree.sh indexed mode (hamming ≤5):**
    -   **Use for:** Scenarios requiring detection up to 5 substitutions while maintaining hamming distance
    -   **Performance:** Good recall for 4-5 mismatch spacers without the false positive explosion of edit distance
    -   **Advantages:** Extends beyond bowtie1's 3-mismatch limitation while avoiding indel-associated false positives
    -   **Limitations:** More computationally intensive than bowtie1, still limited to substitutions only
    -   **When to use:** When analyzing divergent sequences or when increased sensitivity is needed beyond 3 mismatches
3.  **Sassy (edit distance) - Specific applications only:**
    -   **Use for:**
        -   Small datasets where computational cost is acceptable
        -   Experimental setups where mutation type (substitution vs indel) is of research interest
        -   Comparative studies of escape mutation types in controlled systems
        -   Methodological validation and establishing baseline performance
        -   Low-accuracy sequencing (e.g., Oxford Nanopore R9) where indel tolerance may be necessary
    -   **Performance:** Perfect recall (100%), supports arbitrary edit distances
    -   **Limitations:** Massive computational requirements (\~1M CPU seconds for 5% subsample),
    -   **Critical note:** We recommend sassy only for specialized applications where its unique capabilities (perfect recall + arbitrary edit distance) are essential and computational resources are available
4.  **BLASTn-short - Parameter-dependent performance:**
    -   **Use for:** Legacy compatibility, when familiarity with BLAST ecosystem is important
    -   **Critical considerations:** Performance heavily dependent on `-max_target_seqs` parameter; default value significantly impacts high-abundance spacer detection
    -   **Our analysis:** Used most sensitive parameters (lowest word size, high e-value, `-max_target_seqs 100000`)
    -   **Advantages:** Familiar to many researchers, well-documented
    -   **Limitations:** Lower recall than bowtie1, especially for high-abundance targets; parameter sensitivity requires careful configuration

**Algorithmic Insights:**

A key finding is that tools differ not because they are "bad" but because their algorithms solve different computational problems. Edit/affine-based algorithms (bowtie2, minimap2, BLAST, sassy) naturally report more matches than hamming-based ones (bowtie1, indelfree.sh) when using the same numeric threshold - this reflects fundamental algorithmic differences rather than tool quality. For CRISPR spacer-protospacer matching, where biological evidence strongly supports substitution-dominant mutation patterns, hamming-based approaches are more appropriate.

**Tool Performance Patterns and Consistency:**

The results (@fig-tool-performance, @fig-recall demonstrate consistent tool performance patterns across both simulated and real datasets, validating our methodological approach while revealing clear performance hierarchies. At hamming distance ≤3, Bowtie1 achieved recall exceeding 0.95 on both dataset types, substantially outperforming other tools while maintaining low computational costs (@sec-resource-usage). This performance remained stable across dataset scales, from small synthetic datasets (100k spacers) to the full IMG/VR4 HQ dataset (3.8M spacers, 18.9 Gbp), demonstrating robust scaling properties.

Performance variation with spacer occurrence frequency revealed tool-specific algorithmic limitations (\@ sec-abundance-performance). While Bowtie1 maintained consistent recall across the entire occurrence spectrum, other tools exhibited systematic performance degradation at higher occurrence frequencies. StrobeAlign and Minimap2 showed particularly steep declines, likely reflecting seed selection heuristics designed for their primary long-read mapping applications where reference uniqueness is typically assumed. Critically, spacers with occurrence frequencies exceeding 1000 represent less than 0.01% of the dataset (Supplementary Figure S10), indicating that while this phenomenon is measurable, its practical impact on most analyses is minimal.

More significantly, tool performance differences manifested across the full occurrence spectrum, not solely at extreme values. Even at moderate occurrence frequencies (10-100 matches), meaningful sensitivity differences emerged between tools (\@ fig-recall), with Bowtie1 maintaining 5-10% higher recall than most alternatives. The pairwise comparison matrices (@fig-pairwise) quantified this effect: Bowtie1 identified 50,000-150,000 more unique alignment regions than other top-performing tools on the IMG/VR4 dataset. These differences accumulate across millions of spacers, potentially affecting conclusions about virus-host interaction networks and MGE host range estimates.

**Practical Implications:**

Of specific concern is the relatively high number of alignments missed by blastn-short at default parameters, which is currently common in published analyses. Missing genuine spacer-protospacer pairs can significantly impact downstream conclusions about MGE host range, virus-host networks, and CRISPR system evolution. Our analysis suggests that many published studies using blastn-short may have substantially underestimated the number of spacer-protospacer matches, particularly for high-abundance targets.

**Context-Dependent Considerations:**

Experimental and analytical context must be considered when selecting tools:

-   **Large-scale meta-analyses:** Favor bowtie1 for high recall and computational efficiency. In these studies where spacers and targets may not co-occur (from different samples/environments), high recall is critical while acknowledging that similarity implies ancestral encounters rather than current infectivity. Computational Feasibility and Database Growth:\*\*

Resource usage analysis (@sec-resource-usage) reveals that tool selection increasingly constrains analytical possibilities as databases grow. The rapid expansion of both spacer databases (366,799 in 2017 to 3,826,979 in 2023) and viral metagenomes creates a widening computational gap between exhaustive and heuristic approaches.

Exhaustive tools, despite guaranteeing perfect recall, scale poorly with database size. Sassy required approximately 1 million CPU-seconds for the 5% IMG/VR4 subsample; extrapolation to the full dataset suggests greater than 20 million CPU-seconds (approximately 230 CPU-years) would be required. This computational cost renders exhaustive searches impractical for routine analysis, limiting their utility to validation roles on small datasets or methodological studies. Similarly, indelfree.sh in bruteforce mode, while supporting hamming distance constraints, faced comparable scaling limitations.

Heuristic tools demonstrated orders-of-magnitude superior efficiency. Bowtie1 completed the full IMG/VR4 dataset search in 12-36 hours wall time using 64 threads with peak memory under 12 GB. Critically, Bowtie1 exhibited near-linear scaling across our subsample series (421 contigs to 421,431 contigs), suggesting continued feasibility as databases further expand. Other heuristic tools showed varying scaling properties: Bowtie2 and StrobeAlign maintained similar efficiency to Bowtie1, while MMseqs2 required substantially higher memory (100-200 GB) though achieving comparable wall time. BLASTn demonstrated intermediate but highly variable performance, with runtime disproportionately affected by high-abundance spacers and parameter choices.

These computational constraints are not merely technical inconveniences but fundamental limitations on research scope. As databases approach terabase scales, only tools with near-linear scaling properties will remain viable for comprehensive analyses. Tool selection must therefore balance sensitivity requirements against computational realities, favoring approaches sustainable as data volumes continue exponential growth - **CRISPR array context:** Spacers from complete arrays provide additional information (order, genomic location, host genome origin). Recent studies (Mitrofanov et al., Vink et al.) reveal system-specific spacer loss patterns and mismatch tolerance, which may inform post-search verification.

-   **Low-complexity filtering:** Regardless of tool choice, applying DUST masking or similar complexity filtering (e.g., ldust from minimap2, BBDuk from bbmap) prior to searching is prudent to reduce spurious matches from repetitive regions.

Another consideration should be the source of the spacer data: spacers sequences extracted from raw NGS data and spacers extracted from assembled CRISPR arrays (either from assembled or long read sequencing). Specifically, spacers from complete arrays present additional information, namely the location and order of the spacers within the array, and the observation they originate from the same host genome. Notably, a recent in-depth study by Mitrofanov et al @Mitrofanov2025, investigating the mutational landscape of repeats across many isolate prokaryote genomes, have identified patterns of spacer loss based on system sub/type and location. A similar meta-analysis of spacer mutations by Vink et al @Vink2021, have revealed that different CRISPR subtypes exhibit varying tolerance for mismatches within the spacer sequences, with most matched spacers containing three or fewer mismatched nucleotides. This aligns with our current general recommendation of using Bowtie1. Additionally, Vink et al observed that Type I-E and Type II systems preferentially target template strands while Type I-A, I-B, and Type III systems prefer coding strands, emphasizing system-specific characteristics which may also inform post-search verification methods (albeit this may require additional information, such as the sequences orientation or coding potential, and the CRISPR system subtype associated with the spacer).

### Biological Interpretation and Potential False Positives

While our technical comparison focuses on tool performance, the biological interpretation of identified matches also requires careful consideration. The arms race between prokaryotes and MGEs creates a complex landscape where simple sequence matching may not directly translate to genuine host-parasite relationships. We identified several scenarios that could lead to false positive assignments:

1.  **Low Complexity Sequence Matches**: Independently of the tool choice, low-complexity (regions with highly skewed GC content, or composed of many repeated sequences) can be susceptible to spurious matches. Low complexity regions may be present in both the virus target set, or in the spacer set, where some non-CRISPR repeated sequences may have been misclassified as such. While certain tools employ filters and heuristics to mitigate the effect of low complexity regions, a prudent procedure should include a step separated from the search, to specifically identify, filter or mask the spacer and virus sets. Dustmasker [@Morgulis_2006], or a similar tool (e.g. ldust from minimap, or BBDuk from bbmap) could be used prior to the search.

2.  **Common Sequence Motifs**: Some matches may correspond to highly conserved sequences shared across various biological systems. For instance, horizontal gene transfer events can lead to the spread of similar sequences across diverse MGEs, potentially creating spurious matches that don't reflect direct host-MGE interactions. An example of potential HGT mediated matches was described by Kosmopoulos et al. 2023, where a transposon-mediated transferred of a phage lysin gene (to the host genome) created a true sequence similarity (which was verified by the authors using a combination of sequencing technologies) [@Kosmopoulos_2023]. Even if anecdotally observed, this suggests that an unknown number of observed "good" alignments may be due to HGT, which in the absence of additional information, could not be ruled out as a false positive.

3.  **Self-Targeting Events**: Some matches may represent CRISPR targeting of host genes [@Wimmer_2020]. Previous studies estimated a varying amount of these actually target sequences with putative exogenous origin such as prophages, ranging from \~50% [@Stern_2010], to \~80% [@Shmakov_2017]. In Shmakov et al., the authors estimate non-defence targeting is likely a rare event. So far, most observations of non-defence (or counter defence) molecular functions of CRISPRs did not directly involve the spacer sequences, but rather the Cas genes or related effectors. Some observed functions include genome remodeling and evolution, or temporal regulation of gene expression. For example, in *Francisella novicida*, Sampson et al. 2013 demonstrated that certain lipoprotein production is mediated by a CRISPR system [@Sampson_2013].

4.  **non-chromosomal replicon encoded CRISPRs**: Similarly to the potential of CRISPR systems to act in non-immune functions, in certain scenarios spacers may be acquired from non-MGE replicons, or be carried (even if partially) by mobile elements. While some types are known to be chromosomal, others are known to be carried entirely by plasmids (i.e. both the Cas proteins and the array loci are on the plasmid), for example in various halophilic archaea [@Maier_2018]. A recent study by Zhang et al [@Zhang_2025] observed similar phenomena in the human gut microbiome, specifically in *Bifidobacterium longum*. Another non-MGE targeting phenomena in archaea was described by Turgeman-Grott et al. [@Turgeman_Grott_2018], where inter-species spacers (targeting genes from related species) were demonstrated to be common in archaea, at least in the context of cellular mating. Another confounding factor is the potential of certain MGEs to target host genes, potentially for regulatory functions, or as counter-defense mechanisms[@Shmakov_2023]. Shmakov et al. 2023 have identified widespread CRISPR-derived phage-encoded mini-arrays, which can hijack and interfere with their host native system.

### Study Limitations

**Synthetic Dataset Characteristics:**

The synthetic data was generated with sequence characteristics matched to real biological sequences, including GC content matched to iPHoP spacer data (\~49%), simulated contig GC% and length distributions based on IMG/VR4 characteristics (\~46% GC), and verification that k-mer distributions and sequence complexity match real data (see supplementary notebook: spacer_inspection.ipynb). However, real biological sequences have additional complexities not fully captured, including locus-specific composition biases, regional variation in nucleotide frequencies, and evolutionary constraints that shape sequence structure. These differences should be considered when interpreting results, though our enhanced synthetic dataset provides substantially improved realism compared to purely random sequences.

**Distance Metric Focus:**

Our analysis primarily focuses on hamming distance (substitutions only) which we argue aligns with the underlying biological question. While we demonstrate that edit distance dramatically increases false positives (\>10% for edit \>3 vs \<1% for hamming ≤3), we acknowledge that rare cases exist where frame-preserving indels (multiples of 3 bp) could indicate genuine interactions under strong selection. We used sassy to comprehensively test edit distances up to 5, confirming our recommendation against routine use of edit distance for most applications due to prohibitive computational costs and false positive rates. For specialized applications requiring indel detection (e.g., low-accuracy long-read sequencing, experimental mutation-type studies), sassy provides perfect recall but at massive computational cost (\~1M CPU seconds for 5% subsample at 21k contigs, with ≤5 edits). We note that while long-read technologies are attractive for CRISPR arrays (which are repetitive and prone to short-read misassembly), alignment quality cannot exceed underlying sequencing accuracy.

**Sequencing Technology Considerations:**

Our recommendations are primarily based on Illumina-derived assembled sequences where sequencing-induced indels are rare with sufficient depth. For other technologies (Oxford Nanopore R9, PacBio CLR) or low-depth datasets using raw reads, different considerations may apply. However, we argue that even in these cases, biological indels remain rare compared to substitutions, and the false positive explosion with edit distance must be carefully weighed against potential benefits.

**Parameter Space and Tool Versions:**

Tools were not exhaustively tested across all possible parameter combinations, and further optimization may be possible for specific use cases. Several tools presented version-specific challenges: MMseqs2's latest release version had frequent crashes requiring use of the latest GitHub commit, and various index construction parameters (offset rate, seed selection) may affect performance in ways not fully explored. We focused on parameters maximizing sensitivity and avoiding artificial limitations on multiple match detection, representing realistic use cases rather than exhaustive parameter sweeps.

**Computational Resource Constraints:**

Exhaustive tools (Sassy, indelfree.sh bruteforce mode) were not run on the full HQ benchmark dataset due to prohibitive computational costs. Our extrapolations are based on smaller subsamples (ranging from 0.0005× to 0.1×, corresponding to 279 to 42,143 contigs), and actual performance on the full dataset might differ from these estimates. However, the consistent scaling patterns observed across subsample sizes suggest that our computational cost projections are reasonable approximations.

**Sample Size and Scale:**

The synthetic dataset is smaller than the real dataset, though this enabled controlled testing of rare scenarios like ultra-high spacer occurrence rates. We employed stratified subsampling of real data (IMG/VR4 HQ contigs at 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, and 1.0 fractions) to assess tool behavior across different database scales, finding consistent performance patterns suggesting our recommendations are robust across database sizes ranging from 279 contigs (7 Mbp) to 421,431 contigs (18.9 Gbp).

### Future Directions

Several research directions emerge from this work that could refine tool selection and improve spacer-protospacer matching accuracy. First, systematic experimental validation comparing substitution versus indel frequencies in phage escape mutations across diverse CRISPR-Cas systems would provide direct evidence for or against our hamming distance preference. While existing studies predominantly report substitutions [@Deveau2008; @Semenova2011; @Fineran2014], comprehensive quantitative comparisons across mutation types remain lacking.

Second, investigation of frame-preserving indels (3bp multiples) as indicators of strong selection in coding regions could reveal rare but biologically significant patterns. Such indels would maintain reading frame integrity while potentially disrupting CRISPR targeting, representing adaptations under particularly strong selective pressure.

Third, incorporation of CRISPR subtype information could refine matching strategies. Recent work by Mitrofanov et al. [@Mitrofanov2025] on spacer loss patterns and Vink et al. [@Vink2021] on mismatch tolerance differences across CRISPR subtypes suggests that system-specific characteristics could inform both search parameters and post-search verification. Type I-E and Type II systems preferentially target template strands while Type I-A, I-B, and Type III systems prefer coding strands, information that could enhance match validation when combined with strand orientation and coding potential analysis.

Fourth, development of purpose-built tools for spacer-protospacer matching that combine bowtie1-level computational efficiency with extended hamming distance support (≥4 substitutions) would fill a practical gap. Current options either sacrifice sensitivity (bowtie1 maximum 3 mismatches) or computational efficiency (indelfree.sh indexed mode).

Finally, integrated workflows incorporating complexity filtering, post-search verification (validating tool reports), phylogenetic context analysis (i.e. lineage of bacteria encoding a spacer and the lineage of the phage it is matching to), and genomic location assessment (some CRISPR substypes preferentially acquire sequences from coding regions) would provide more robust inference frameworks. Such workflows could systematically address other confounding factors including low-complexity sequences, horizontal gene transfer events [@Kosmopoulos_2023], self-targeting [@Wimmer_2020; @Stern_2010; @Shmakov_2017], non-defense functions [@Sampson_2013], plasmid-encoded CRISPR systems [@Maier_2018; @Zhang_2025], inter-species targeting [@Turgeman_Grott_2018], and phage-encoded mini-arrays [@Shmakov_2023].

## Conclusion

Our comprehensive comparison of spacer-protospacer search tools, combining synthetic datasets with known ground truth and real-world metagenomic data, reveals critical insights for tool selection and establishes evidence-based recommendations.

**Key Findings:**

1.  **Distance metric choice is critical:** Hamming distance (≤3 substitutions) maintains \<1% false positive rate while edit distance (\>3 edits) leads to \>10% false positives. Biological evidence strongly supports hamming distance: indels are \~4× rarer than substitutions, most escape mutations are single substitutions, and phage coding-dense genomes make frameshift-inducing indels often lethal.

2.  **Tool performance varies by algorithmic approach:** Tools differ not in quality but in the computational problems they solve. Edit/affine-based algorithms naturally report more matches than hamming-based ones - understanding these algorithmic differences is essential for appropriate tool selection.

3.  **Abundance sensitivity distinguishes tools:** The primary performance differentiator is handling high-abundance spacers (\>1000 occurrences). Bowtie1 maintains \>97% recall for highly repetitive sequences, while other tools show systematic decline due to heuristics designed for different use cases.

4.  **Current practices may miss many matches:** BLASTn-short at default parameters misses substantially more matches than bowtie1, particularly for high-abundance targets. Many published studies likely underestimate spacer-protospacer matches.

**Evidence-Based Recommendations:**

-   **Most applications:** Bowtie1 with hamming ≤3 (high recall, low false positives, excellent computational efficiency)
-   **Extended mismatches (4-5):** Indelfree.sh indexed mode (avoids edit distance false positive explosion)
-   **Specialized only:** Sassy for small datasets when mutation type matters or perfect recall is essential (computationally prohibitive for large-scale analysis)

**Broader Implications:**

The interpretation of spacer-protospacer matches requires careful consideration of biological context beyond tool performance: low-complexity sequences, horizontal gene transfer, self-targeting, and mobile element-encoded CRISPRs can all complicate straightforward interpretation. Proper workflow should include complexity filtering, post-search verification of alignment quality, and contextual analysis of genomic location and phylogeny.

Our findings emphasize that tool selection should be guided by understanding algorithmic assumptions and their alignment with biological expectations. As CRISPR spacer and viral databases continue growing rapidly (from 366,799 spacers in 2017 to 3,835,942 in 2023), choosing appropriate tools becomes increasingly critical for accurate host-MGE interaction inference.

We provide not just tool performance metrics but a framework for understanding why tools differ and how to select appropriate methods for specific research contexts. This work enables more accurate inference of virus-host relationships and CRISPR system evolution across diverse microbial ecosystems.

## Code and data availability

All code generated for this study can be found in the git repository: [github.com/UriNeri/spacer_matching_bench](https://github.com/UriNeri/spacer_matching_bench). All data generated in this project (tool results and the analysed datasets, any sequence data, SLURM logs etc) are available on Zenodo [@zenodo_doi].

## Acknowledgements

Work conducted by the U.S. DOE Joint Genome Institute (https://ror.org/04xm1d337) (SR, UN, APC and BB), a DOE Office of Science User Facility, is supported by the Office of Science of the U.S. DOE operated under Contract DE-AC02-05CH11231.

We would like to thank the following people for their helpful feedback and suggestions: Uri Gophna, Georg Rath, and Ragnar Groot Koerkamp for valuable discussions on distance metrics and tool performance.