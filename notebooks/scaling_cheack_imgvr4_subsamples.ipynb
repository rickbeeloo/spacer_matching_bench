{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis: IMG/VR4 Stratified Subsamples\n",
    "\n",
    "This notebook analyzes tool performance across stratified subsamples of the IMG/VR4 dataset. The subsamples were created using taxonomy-aware, GC-content, and length-stratified sampling to preserve diversity while reducing computational requirements.\n",
    "\n",
    "**Subsamples analyzed**: fractions 0.001, 0.005, 0.01, 0.05, 0.1  \n",
    "**Approach**: Load tool results from each subsample, analyze performance metrics, and compare across scales.\n",
    "\n",
    "Note: Unlike simulated data, we don't have ground truth here, so we focus on:\n",
    "- Number of unique spacer-contig matches found\n",
    "The main goal here:  \n",
    "Are the tools subsampled results indicative on a larger (non sample size / larger sample size) comparison (i.e. can we trust interpration made using the largest subsample)\n",
    "\n",
    "\n",
    "Note2: The actual performence comparisons for the 5 and 10% samples are in Performence_imgvr4.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "os.chdir('/clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/')\n",
    "\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pl.Config(tbl_rows=50, tbl_cols=15)\n",
    "\n",
    "from bench.utils.functions import *\n",
    "from bench.utils.tool_commands import load_tool_configs\n",
    "# Analysis parameters\n",
    "MAX_MISMATCHES = 3\n",
    "base_dir = \"/clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples\"\n",
    "spacers_file = \"/clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/imgvr4_data/spacers/All_CRISPR_spacers_nr_clean.fna\"\n",
    "fractions = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Tool color and marker configuration\n",
    "import json\n",
    "\n",
    "# Create tool-to-style mapping\n",
    "TOOL_COLORS_FILE = \"notebooks/antonio_14_colors.json\"\n",
    "with open(TOOL_COLORS_FILE, 'r') as f:\n",
    "    color_config = json.load(f)\n",
    "TOOL_ORDER = [\n",
    "    'blastn', 'bowtie1', 'bowtie2', 'indelfree_bruteforce', 'indelfree_indexed',\n",
    "    'lexicmap', 'minimap2', 'mmseqs2', 'mummer4', 'sassy', 'strobealign', 'x_mapper'\n",
    "]\n",
    "MARKERS = ['o', 's', '^', 'v', 'D', 'P', '*', 'X', 'h', 'p', '<', '>']\n",
    "TOOL_STYLES = {}\n",
    "for i, tool in enumerate(TOOL_ORDER):\n",
    "    TOOL_STYLES[tool] = {\n",
    "        'color': color_config['hex_colors'][i % len(color_config['hex_colors'])],\n",
    "        'marker': MARKERS[i % len(MARKERS)]\n",
    "    }\n",
    "\n",
    "print(f\"  Max mismatches: {MAX_MISMATCHES}\")\n",
    "print(f\"  Tool styles configured for {len(TOOL_STYLES)} tools\")\n",
    "with open('tool_styles.json', 'w') as f:\n",
    "    json.dump(TOOL_STYLES, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan Subsample Directories and Identify Completed Tools\n",
    "\n",
    "First, we scan each subsample fraction directory and check the SLURM logs to identify which tools completed successfully vs timed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tool_completion(fraction):\n",
    "    \"\"\"Check which tools completed for a given fraction by examining SLURM logs\"\"\"\n",
    "    frac_dir = f\"{base_dir}/fraction_{fraction}\"\n",
    "    log_dir = f\"{frac_dir}/slurm_logs\"\n",
    "    \n",
    "    if not os.path.exists(log_dir):\n",
    "        return {\"completed\": [], \"timed_out\": []} #, \"failed\": []}\n",
    "    \n",
    "    completed = set()\n",
    "    timed_out = set()\n",
    "    # failed = set()\n",
    "    \n",
    "    # Check all .out and .err files\n",
    "    for out_file in glob.glob(f\"{log_dir}/*.out\"):\n",
    "        tool_name = os.path.basename(out_file).replace(\"_long-\", \"-\").split('-')[0]\n",
    "        err_file = out_file.replace('.out', '.err')\n",
    "\n",
    "        \n",
    "        if not os.path.exists(err_file):\n",
    "            continue\n",
    "            \n",
    "        # Read error log to check for timeout\n",
    "        with open(err_file, 'r') as f:\n",
    "            err_content = f.read()\n",
    "            if 'TIME LIMIT' in err_content or 'DUE TO TIME LIMIT' in err_content:\n",
    "                timed_out.add(tool_name)\n",
    "            # elif 'CANCELLED' in err_content or 'FAILED' in err_content:\n",
    "            #     failed.add(tool_name)\n",
    "            else:\n",
    "                # Check if output file exists\n",
    "                output_file = f\"{frac_dir}/raw_outputs/{tool_name}_output.{'sam' if tool_name not in ['blastn', 'lexicmap', 'mmseqs'] else 'tsv'}\"\n",
    "                if tool_name == \"sassy\":\n",
    "                    output_file = f\"{frac_dir}/raw_outputs/sassy.tsv\"\n",
    "                if os.path.exists(output_file) and os.path.getsize(output_file) > 0:\n",
    "                    completed.add(tool_name)\n",
    "    \n",
    "    return {\n",
    "        \"completed\": sorted(list(completed)),\n",
    "        \"timed_out\": sorted(list(timed_out - completed)),  # Remove if completed on resubmit\n",
    "        # \"failed\": sorted(list(failed - completed))\n",
    "    }\n",
    "\n",
    "# Check completion status for all fractions\n",
    "completion_status = {}\n",
    "for frac in fractions:\n",
    "    status = check_tool_completion(frac)\n",
    "    completion_status[frac] = status\n",
    "    print(f\"Fraction {frac}:\")\n",
    "    print(f\"  Completed: {len(status['completed'])} tools - {', '.join(status['completed'])}\")\n",
    "    if status['timed_out']:\n",
    "        print(f\"  Timed out: {', '.join(status['timed_out'])}\")\n",
    "    # if status['failed']:\n",
    "    #     print(f\"  Failed: {', '.join(status['failed'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tool Results from Each Subsample\n",
    "\n",
    "For each fraction, load the tool results using the `read_results` function with proper filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read spacer lengths for filtering\n",
    "spacers = read_fasta(spacers_file)\n",
    "spacer_lendf = pl.DataFrame({\n",
    "    \"spacer_id\": list(spacers.keys()), \n",
    "    \"length\": [len(seq) for seq in spacers.values()]\n",
    "})\n",
    "\n",
    "print(f\"Loaded {len(spacers)} spacers\")\n",
    "print(f\"Length range: {spacer_lendf['length'].min()} - {spacer_lendf['length'].max()} bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load results from all fractions\n",
    "all_results = {}\n",
    "# fractions = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "fractions = [0.001]#, 0.005] #, 0.01, 0.05, 0.1] # starting small\n",
    "\n",
    "for frac in fractions:\n",
    "    print(f\"\\n=== Loading fraction {frac} ===\")\n",
    "    frac_dir = f\"{base_dir}/fraction_{frac}\"\n",
    "    contigs_file = f\"{frac_dir}/subsampled_data/subsampled_contigs.fa\"\n",
    "    \n",
    "    # Only load completed tools\n",
    "    completed_tools = completion_status[frac]['completed']\n",
    "    if not completed_tools:\n",
    "        print(f\"  No completed tools for fraction {frac}, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Load tool configurations\n",
    "    tools = load_tool_configs(\n",
    "        results_dir=frac_dir,\n",
    "        threads=8,\n",
    "        contigs_file=contigs_file,\n",
    "        spacers_file=spacers_file\n",
    "    )\n",
    "    \n",
    "    # Filter to only completed tools\n",
    "    tools_to_load = {k: v for k, v in tools.items() if k in completed_tools}\n",
    "    print(f\"  Loading {len(tools_to_load)} tools: {', '.join(tools_to_load.keys())}\")\n",
    "    \n",
    "    # Read results with max_mismatches filter\n",
    "    try:\n",
    "        results_df = read_results(\n",
    "            tools_to_load,\n",
    "            max_mismatches=MAX_MISMATCHES+2, #tool reported, not validated for the scalling tests\n",
    "            spacer_lendf=spacer_lendf,\n",
    "            ref_file=contigs_file,\n",
    "            threads=8,\n",
    "        )\n",
    "        \n",
    "        # Add fraction column\n",
    "        results_df = results_df.with_columns(pl.lit(frac).alias('fraction'))\n",
    "        results_df.write_parquet(f'results/real_data/subsamples_analysis/alignments_fraction_{frac}.parquet')\n",
    "        \n",
    "        all_results[frac] = results_df\n",
    "        print(f\"  Loaded {results_df.height:,} alignments from {results_df['tool'].n_unique()} tools\")\n",
    "        print(f\"  Unique spacers: {results_df['spacer_id'].n_unique():,}, contigs: {results_df['contig_id'].n_unique():,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading results: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Loaded results from {len(all_results)} fractions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load results from all fractions\n",
    "# fractions = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "all_results = {0.001 :pl.read_parquet(f'results/real_data/subsamples_analysis/alignments_fraction_0.001.parquet')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = [0.005] #, 0.01, 0.05, 0.1] # starting small\n",
    "\n",
    "for frac in fractions:\n",
    "    print(f\"\\n=== Loading fraction {frac} ===\")\n",
    "    frac_dir = f\"{base_dir}/fraction_{frac}\"\n",
    "    contigs_file = f\"{frac_dir}/subsampled_data/subsampled_contigs.fa\"\n",
    "    \n",
    "    # Only load completed tools\n",
    "    completed_tools = completion_status[frac]['completed']\n",
    "    if not completed_tools:\n",
    "        print(f\"  No completed tools for fraction {frac}, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Load tool configurations\n",
    "    tools = load_tool_configs(\n",
    "        results_dir=frac_dir,\n",
    "        threads=8,\n",
    "        contigs_file=contigs_file,\n",
    "        spacers_file=spacers_file\n",
    "    )\n",
    "    \n",
    "    # Filter to only completed tools\n",
    "    tools_to_load = {k: v for k, v in tools.items() if k in completed_tools}\n",
    "    print(f\"  Loading {len(tools_to_load)} tools: {', '.join(tools_to_load.keys())}\")\n",
    "    \n",
    "    # Read results with max_mismatches filter\n",
    "    try:\n",
    "        results_df = read_results(\n",
    "            tools_to_load,\n",
    "            max_mismatches=MAX_MISMATCHES+2, #tool reported, not validated for the scalling tests\n",
    "            spacer_lendf=spacer_lendf,\n",
    "            ref_file=contigs_file,\n",
    "            threads=8,\n",
    "        )\n",
    "        \n",
    "        # Add fraction column\n",
    "        results_df = results_df.with_columns(pl.lit(frac).alias('fraction'))\n",
    "        results_df.write_parquet(f'results/real_data/subsamples_analysis/alignments_fraction_{frac}.parquet')\n",
    "        \n",
    "        all_results[frac] = results_df\n",
    "        print(f\"  Loaded {results_df.height:,} alignments from {results_df['tool'].n_unique()} tools\")\n",
    "        print(f\"  Unique spacers: {results_df['spacer_id'].n_unique():,}, contigs: {results_df['contig_id'].n_unique():,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading results: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Loaded results from {len(all_results)} fractions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Fraction Analysis (No Aggregation)\n",
    "\n",
    "Analyze each fraction separately since they're stratified samples from the same dataset and are not independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each fraction separately (they are NOT independent samples)\n",
    "# For each fraction, we'll compute summary stats\n",
    "\n",
    "per_fraction_stats = {}\n",
    "\n",
    "for frac, results_df in all_results.items():\n",
    "    print(f\"\\n=== Fraction {frac} Statistics ===\")\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"Total alignments: {results_df.height:,}\")\n",
    "    print(f\"Unique spacers: {results_df['spacer_id'].n_unique():,}\")\n",
    "    print(f\"Unique contigs: {results_df['contig_id'].n_unique():,}\")\n",
    "    print(f\"Tools: {results_df['tool'].n_unique()}\")\n",
    "    \n",
    "    # Per-tool summary\n",
    "    tool_summary = results_df.group_by('tool').agg([\n",
    "        pl.col('spacer_id').n_unique().alias('n_unique_spacers'),\n",
    "        pl.col('contig_id').n_unique().alias('n_unique_contigs'),\n",
    "        pl.len().alias('n_total_alignments'),\n",
    "        pl.col('mismatches').mean().alias('mean_mismatches'),\n",
    "        pl.col('mismatches').median().alias('median_mismatches'),\n",
    "        (pl.col('mismatches') == 0).sum().alias('n_perfect_matches'),\n",
    "    ]).sort('n_unique_spacers', descending=True)\n",
    "    \n",
    "    per_fraction_stats[frac] = tool_summary\n",
    "    print(f\"\\nTop 5 tools by unique spacers:\")\n",
    "    print(tool_summary.head(5))\n",
    "\n",
    "# Display all stats\n",
    "print(\"\\n\\n=== Summary Table: All Fractions ===\")\n",
    "for frac in sorted(per_fraction_stats.keys()):\n",
    "    print(f\"\\n--- Fraction {frac} ---\")\n",
    "    print(per_fraction_stats[frac])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalculate Alignments with Parasail for Deterministic Mismatch Counts\n",
    "\n",
    "The tool-reported mismatches can vary. We'll recalculate them deterministically using parasail.\n",
    "This follows the same workflow as the original full-dataset notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For each fraction, recalculate alignments\n",
    "recalculated_results = {}\n",
    "\n",
    "for frac, results_df in all_results.items():\n",
    "    print(f\"\\n=== Recalculating alignments for fraction {frac} ===\")\n",
    "    frac_dir = f\"{base_dir}/fraction_{frac}\"\n",
    "    contigs_file = f\"{frac_dir}/subsampled_data/subsampled_contigs.fa\"\n",
    "    \n",
    "    # Get unique regions (spacer-contig pairs with coordinates)\n",
    "    unique_regions = results_df.select([\n",
    "        \"spacer_id\", \"contig_id\", \"strand\", \"start\", \"end\"\n",
    "    ]).unique()\n",
    "    \n",
    "    print(f\"Unique regions to verify: {unique_regions.height:,}\")\n",
    "    \n",
    "    # Populate with spacer sequences\n",
    "    print(\"  Loading spacer sequences...\")\n",
    "    unique_regions = populate_pldf_withseqs_needletail(\n",
    "        seqfile=spacers_file,\n",
    "        pldf=unique_regions,\n",
    "        chunk_size=2000000,\n",
    "        reverse_by_strand_col=False,\n",
    "        trim_to_region=False,\n",
    "        idcol=\"spacer_id\",\n",
    "        seqcol=\"spacer_seq\"\n",
    "    )\n",
    "    \n",
    "    # Populate with contig sequences (trimmed to region)\n",
    "    print(\"  Loading contig sequences...\")\n",
    "    unique_regions = populate_pldf_withseqs_needletail(\n",
    "        seqfile=contigs_file,\n",
    "        trim_to_region=True,\n",
    "        reverse_by_strand_col=True,\n",
    "        chunk_size=200000,\n",
    "        pldf=unique_regions,\n",
    "        idcol=\"contig_id\",\n",
    "        start_col=\"start\",\n",
    "        end_col=\"end\",\n",
    "        strand_col=\"strand\",\n",
    "        seqcol=\"contig_seq\"\n",
    "    )\n",
    "    \n",
    "    # Recalculate mismatches using parasail\n",
    "    print(\"  Recalculating mismatches with parasail...\")\n",
    "    recalced = test_alignment_polars(\n",
    "        results=unique_regions,\n",
    "        return_deviations=False,\n",
    "        ignore_region_strands=True\n",
    "    )\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    recalced = recalced.rename({\"alignment_test\": \"recalced_mismatches\"})\n",
    "    \n",
    "    # Join back with original results\n",
    "    results_with_recalc = results_df.join(\n",
    "        recalced[[\"spacer_id\", \"contig_id\", \"strand\", \"start\", \"end\", \n",
    "                  \"spacer_seq\", \"contig_seq\", \"recalced_mismatches\"]],\n",
    "        on=[\"spacer_id\", \"contig_id\", \"strand\", \"start\", \"end\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Rename original mismatches for clarity\n",
    "    results_with_recalc = results_with_recalc.rename({\n",
    "        \"mismatches\": \"tool_reported_mismatches\"\n",
    "    }).rename({\n",
    "        \"recalced_mismatches\": \"mismatches\"\n",
    "    })\n",
    "    \n",
    "    # Check for deviations\n",
    "    results_with_recalc = results_with_recalc.with_columns(\n",
    "        (pl.col(\"mismatches\") - pl.col(\"tool_reported_mismatches\")).alias(\"deviation\")\n",
    "    )\n",
    "    \n",
    "    n_deviations = results_with_recalc.filter(pl.col(\"deviation\") != 0).height\n",
    "    print(f\"  Alignments with deviations: {n_deviations:,} ({100*n_deviations/results_with_recalc.height:.2f}%)\")\n",
    "    \n",
    "    # Filter to max_mismatches after recalculation\n",
    "    results_with_recalc = results_with_recalc.filter(pl.col(\"mismatches\") <= MAX_MISMATCHES)\n",
    "    print(f\"  Alignments after filtering (≤{MAX_MISMATCHES} mismatches): {results_with_recalc.height:,}\")\n",
    "    \n",
    "    recalculated_results[frac] = results_with_recalc\n",
    "\n",
    "print(f\"\\n✓ Recalculated alignments for {len(recalculated_results)} fractions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated Per-Fraction Statistics (with Recalculated Mismatches)\n",
    "\n",
    "Now compute statistics using the recalculated mismatches from parasail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute statistics with recalculated mismatches\n",
    "updated_per_fraction_stats = {}\n",
    "\n",
    "for frac, results_df in recalculated_results.items():\n",
    "    print(f\"\\n=== Fraction {frac} (Recalculated Mismatches) ===\")\n",
    "    \n",
    "    # Per-tool summary\n",
    "    tool_summary = results_df.group_by('tool').agg([\n",
    "        pl.col('spacer_id').n_unique().alias('n_unique_spacers'),\n",
    "        pl.col('contig_id').n_unique().alias('n_unique_contigs'),\n",
    "        pl.len().alias('n_total_alignments'),\n",
    "        pl.col('mismatches').mean().alias('mean_mismatches'),\n",
    "        pl.col('mismatches').median().alias('median_mismatches'),\n",
    "        (pl.col('mismatches') == 0).sum().alias('n_perfect_matches'),\n",
    "        pl.col('deviation').mean().alias('mean_deviation_from_tool'),\n",
    "        (pl.col('deviation') != 0).sum().alias('n_with_deviation'),\n",
    "    ]).sort('n_unique_spacers', descending=True)\n",
    "    \n",
    "    updated_per_fraction_stats[frac] = tool_summary\n",
    "    display(tool_summary)\n",
    "\n",
    "# Save updated stats\n",
    "print(\"\\n✓ Updated statistics computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations: Comparing Tools Across Fractions\n",
    "\n",
    "Plot tool performance metrics across subsample sizes using the recalculated mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results/real_data/subsamples_analysis', exist_ok=True)\n",
    "# Combine stats from all fractions for plotting\n",
    "plot_data_list = []\n",
    "for frac in sorted(updated_per_fraction_stats.keys()):\n",
    "    stats_df = updated_per_fraction_stats[frac].with_columns(pl.lit(frac).alias('fraction'))\n",
    "    plot_data_list.append(stats_df)\n",
    "\n",
    "combined_stats = pl.concat(plot_data_list)\n",
    "\n",
    "# Plot 1: Number of unique spacers found per tool across fractions\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Plot tools in consistent order with assigned colors/markers\n",
    "for tool in TOOL_ORDER:\n",
    "    tool_data = combined_stats.filter(pl.col('tool') == tool)\n",
    "    if tool_data.height == 0:\n",
    "        continue\n",
    "    tool_data = tool_data.sort('fraction')\n",
    "    style = TOOL_STYLES.get(tool, {'color': 'gray', 'marker': 'o'})\n",
    "    \n",
    "    ax.plot(tool_data['fraction'].to_list(), \n",
    "            tool_data['n_unique_spacers'].to_list(), \n",
    "            marker=style['marker'], \n",
    "            color=style['color'],\n",
    "            label=tool, \n",
    "            linewidth=2, \n",
    "            markersize=8, \n",
    "            alpha=0.85)\n",
    "\n",
    "ax.set_xlabel('Subsample Fraction', fontsize=13)\n",
    "\n",
    "ax.set_ylabel('Number of Unique Spacers Found', fontsize=13)\n",
    "print(f\"✓ Saved unique spacers plot (≤{MAX_MISMATCHES} mismatches)\")\n",
    "\n",
    "ax.set_title(f'Tool Performance: Unique Spacers vs Subsample Size (Recalculated ≤{MAX_MISMATCHES} mismatches)', plt.show()\n",
    "\n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "plt.savefig('results/real_data/subsamples_analysis/unique_spacers_vs_fraction.png', dpi=300, bbox_inches='tight')\n",
    "ax.set_xscale('log')\n",
    "plt.savefig('results/real_data/subsamples_analysis/unique_spacers_vs_fraction.pdf', bbox_inches='tight')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10, framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3, which='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Number of unique contigs matched per tool across fractions\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Plot tools in consistent order with assigned colors/markers\n",
    "for tool in TOOL_ORDER:\n",
    "    tool_data = combined_stats.filter(pl.col('tool') == tool)\n",
    "    if tool_data.height == 0:\n",
    "        continue\n",
    "    tool_data = tool_data.sort('fraction')\n",
    "    style = TOOL_STYLES.get(tool, {'color': 'gray', 'marker': 'o'})\n",
    "    \n",
    "    ax.plot(tool_data['fraction'].to_list(), \n",
    "            tool_data['n_unique_contigs'].to_list(), \n",
    "            marker=style['marker'],\n",
    "            color=style['color'],\n",
    "            label=tool, \n",
    "            linewidth=2, \n",
    "            markersize=8,\n",
    "            alpha=0.85)\n",
    "\n",
    "ax.set_xlabel('Subsample Fraction', fontsize=12)\n",
    "ax.set_ylabel('Number of Unique Contigs Matched', fontsize=12)\n",
    "ax.set_title(f'Tool Performance: Unique Contigs Across Subsample Sizes (≤{MAX_MISMATCHES} mismatches)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "print(f\"✓ Saved contigs plot (≤{MAX_MISMATCHES} mismatches)\")\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.savefig('results/real_data/subsamples_analysis/contigs_by_fraction.png', dpi=150, bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/real_data/subsamples_analysis/contigs_by_fraction.pdf', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In the these selected subsampling sizes, the results of each tool appear consist (similar ratios compared to the same tool but the other size fractions).\n",
    "This suggests we should be able to extrapolate/assume that should we have the CPU time to run all tools on the entire dataset (no subsampling) the results would be qualitative similar (from tool vs tool comparison perspective)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
