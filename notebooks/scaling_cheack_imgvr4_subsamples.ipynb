{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis: IMG/VR4 Stratified Subsamples\n",
    "\n",
    "This notebook analyzes tool performance across stratified subsamples of the IMG/VR4 dataset. The subsamples were created using taxonomy-aware, GC-content, and length-stratified sampling to preserve diversity while reducing computational requirements.\n",
    "\n",
    "**Subsamples analyzed**: fractions 0.001, 0.005, 0.01, 0.05, 0.1  \n",
    "**Approach**: Load tool results from each subsample, analyze performance metrics, and compare across scales.\n",
    "\n",
    "Note: Unlike simulated data, we don't have ground truth here, so we focus on:\n",
    "- Number of unique spacer-contig matches found\n",
    "The main goal here:  \n",
    "Are the tools subsampled results indicative on a larger (non sample size / larger sample size) comparison (i.e. can we trust interpration made using the largest subsample)\n",
    "\n",
    "\n",
    "Note2: The actual performence comparisons for the 5 and 10% samples are in Performence_imgvr4.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Max mismatches: 3\n",
      "  Tool styles configured for 12 tools\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "os.chdir('/clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/')\n",
    "\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pl.Config(tbl_rows=50, tbl_cols=15)\n",
    "\n",
    "from bench.utils.functions import read_fasta,read_results\n",
    "from bench.utils.tool_commands import load_tool_configs\n",
    "# Analysis parameters\n",
    "MAX_MISMATCHES = 3\n",
    "base_dir = \"/clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples\"\n",
    "spacers_file = \"/clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/imgvr4_data/spacers/All_CRISPR_spacers_nr_clean.fna\"\n",
    "fractions = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Tool color and marker configuration\n",
    "import json\n",
    "\n",
    "# Create tool-to-style mapping\n",
    "TOOL_COLORS_FILE = \"notebooks/antonio_14_colors.json\"\n",
    "with open(TOOL_COLORS_FILE, 'r') as f:\n",
    "    color_config = json.load(f)\n",
    "TOOL_ORDER = [\n",
    "    'blastn', 'bowtie1', 'bowtie2', 'indelfree_bruteforce', 'indelfree_indexed',\n",
    "    'lexicmap', 'minimap2', 'mmseqs2', 'mummer4', 'sassy', 'strobealign', 'x_mapper'\n",
    "]\n",
    "MARKERS = ['o', 's', '^', 'v', 'D', 'P', '*', 'X', 'h', 'p', '<', '>']\n",
    "TOOL_STYLES = {}\n",
    "for i, tool in enumerate(TOOL_ORDER):\n",
    "    TOOL_STYLES[tool] = {\n",
    "        'color': color_config['hex_colors'][i % len(color_config['hex_colors'])],\n",
    "        'marker': MARKERS[i % len(MARKERS)]\n",
    "    }\n",
    "\n",
    "print(f\"  Max mismatches: {MAX_MISMATCHES}\")\n",
    "print(f\"  Tool styles configured for {len(TOOL_STYLES)} tools\")\n",
    "with open('notebooks/tool_styles.json', 'w') as f:\n",
    "    json.dump(TOOL_STYLES, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan Subsample Directories and Identify Completed Tools\n",
    "\n",
    "First, we scan each subsample fraction directory and check the SLURM logs to identify which tools completed successfully vs timed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction 0.001:\n",
      "  Completed: 11 tools - blastn, bowtie1, bowtie2, indelfree_bruteforce, indelfree_indexed, minimap2, mmseqs, mummer4, sassy, strobealign, x_mapper\n",
      "\n",
      "Fraction 0.005:\n",
      "  Completed: 12 tools - blastn, bowtie1, bowtie2, indelfree_bruteforce, indelfree_indexed, lexicmap, minimap2, mmseqs, mummer4, sassy, strobealign, x_mapper\n",
      "\n",
      "Fraction 0.01:\n",
      "  Completed: 12 tools - blastn, bowtie1, bowtie2, indelfree_bruteforce, indelfree_indexed, lexicmap, minimap2, mmseqs, mummer4, sassy, strobealign, x_mapper\n",
      "\n",
      "Fraction 0.05:\n",
      "  Completed: 12 tools - blastn, bowtie1, bowtie2, indelfree_bruteforce, indelfree_indexed, lexicmap, minimap2, mmseqs, mummer4, sassy, strobealign, x_mapper\n",
      "\n",
      "Fraction 0.1:\n",
      "  Completed: 10 tools - blastn, bowtie1, bowtie2, indelfree_indexed, lexicmap, minimap2, mmseqs, mummer4, strobealign, x_mapper\n",
      "  Timed out: indelfree_bruteforce, sassy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_tool_completion(fraction):\n",
    "    \"\"\"Check which tools completed for a given fraction by examining SLURM logs\"\"\"\n",
    "    frac_dir = f\"{base_dir}/fraction_{fraction}\"\n",
    "    log_dir = f\"{frac_dir}/slurm_logs\"\n",
    "    \n",
    "    if not os.path.exists(log_dir):\n",
    "        return {\"completed\": [], \"timed_out\": []} #, \"failed\": []}\n",
    "    \n",
    "    completed = set()\n",
    "    timed_out = set()\n",
    "    # failed = set()\n",
    "    \n",
    "    # Check all .out and .err files\n",
    "    for out_file in glob.glob(f\"{log_dir}/*.out\"):\n",
    "        tool_name = os.path.basename(out_file).replace(\"_long-\", \"-\").split('-')[0]\n",
    "        err_file = out_file.replace('.out', '.err')\n",
    "\n",
    "        \n",
    "        if not os.path.exists(err_file):\n",
    "            continue\n",
    "            \n",
    "        # Read error log to check for timeout\n",
    "        with open(err_file, 'r') as f:\n",
    "            err_content = f.read()\n",
    "            if 'TIME LIMIT' in err_content or 'DUE TO TIME LIMIT' in err_content:\n",
    "                timed_out.add(tool_name)\n",
    "            # elif 'CANCELLED' in err_content or 'FAILED' in err_content:\n",
    "            #     failed.add(tool_name)\n",
    "            else:\n",
    "                # Check if output file exists\n",
    "                output_file = f\"{frac_dir}/raw_outputs/{tool_name}_output.{'sam' if tool_name not in ['blastn', 'lexicmap', 'mmseqs'] else 'tsv'}\"\n",
    "                if tool_name == \"sassy\":\n",
    "                    output_file = f\"{frac_dir}/raw_outputs/sassy.tsv\"\n",
    "                if os.path.exists(output_file) and os.path.getsize(output_file) > 0:\n",
    "                    completed.add(tool_name)\n",
    "    \n",
    "    return {\n",
    "        \"completed\": sorted(list(completed)),\n",
    "        \"timed_out\": sorted(list(timed_out - completed)),  # Remove if completed on resubmit\n",
    "        # \"failed\": sorted(list(failed - completed))\n",
    "    }\n",
    "\n",
    "# Check completion status for all fractions\n",
    "completion_status = {}\n",
    "for frac in fractions:\n",
    "    status = check_tool_completion(frac)\n",
    "    completion_status[frac] = status\n",
    "    print(f\"Fraction {frac}:\")\n",
    "    print(f\"  Completed: {len(status['completed'])} tools - {', '.join(status['completed'])}\")\n",
    "    if status['timed_out']:\n",
    "        print(f\"  Timed out: {', '.join(status['timed_out'])}\")\n",
    "    # if status['failed']:\n",
    "    #     print(f\"  Failed: {', '.join(status['failed'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tool Results from Each Subsample\n",
    "\n",
    "For each fraction, load the tool results using the `read_results` function with proper filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3882812 spacers\n",
      "Length range: 25 - 40 bp\n"
     ]
    }
   ],
   "source": [
    "# Read spacer lengths for filtering\n",
    "spacers = read_fasta(spacers_file)\n",
    "spacer_lendf = pl.DataFrame({\n",
    "    \"spacer_id\": list(spacers.keys()), \n",
    "    \"length\": [len(seq) for seq in spacers.values()]\n",
    "})\n",
    "\n",
    "print(f\"Loaded {len(spacers)} spacers\")\n",
    "print(f\"Length range: {spacer_lendf['length'].min()} - {spacer_lendf['length'].max()} bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading fraction 0.001 ===\n",
      "  Loading 10 tools: blastn, bowtie1, bowtie2, indelfree_bruteforce, indelfree_indexed, minimap2, mummer4, sassy, strobealign, x_mapper\n",
      "\n",
      "Reading results for blastn...\n",
      "File size: 3.10 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs//blastn_output.tsv exists\n",
      "\n",
      "Reading results for bowtie1...\n",
      "File size: 496.00 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs//bowtie1_output.sam exists\n",
      "first line of sam file @HD\tVN:1.0\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_2974659795_000002|2974659795|2974659795\tLN:6543\n",
      "Found 808 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 3897862it [00:03, 1278622.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for bowtie2...\n",
      "File size: 499.48 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs//bowtie2_output.sam exists\n",
      "first line of sam file @HD\tVN:1.5\tSO:unsorted\tGO:query\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_2974659795_000002|2974659795|2974659795\tLN:6543\n",
      "Found 808 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 3894848it [00:03, 1291156.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for indelfree_bruteforce...\n",
      "File size: 99.26 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs//indelfree_bruteforce_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_2974659795_000002|2974659795|2974659795\tLN:6543\n",
      "Found 808 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 649717it [00:02, 304113.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for indelfree_indexed...\n",
      "File size: 18.63 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs//indelfree_indexed_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_2974659795_000002|2974659795|2974659795\tLN:6543\n",
      "Found 808 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 114895it [00:00, 177744.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for minimap2...\n",
      "File size: 0.06 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs//minimap2_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\tGO:query\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_2974659795_000002|2974659795|2974659795\tLN:6543\n",
      "Found 808 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 13it [00:00, 25744.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for mummer4...\n",
      "File size: 4.18 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs//mummer4_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_2974659795_000002|2974659795|2974659795\tLN:6543\n",
      "Found 808 SQ lines, 1 PG lines\n",
      "SAM file needs fixing\n",
      "Rewriting HD line for mummer file\n",
      "SAM file has been fixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 24945it [00:00, 186487.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for sassy...\n",
      "File size: 148590.10 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs//sassy.tsv exists\n",
      "Starting DuckDB Pipeline (Writing to: /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs/sassy_parsed_20260105.parquet)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc57602536e3475d9c551a437a52b373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading new Parquet file into Polars...\n",
      "\n",
      "Reading results for strobealign...\n",
      "File size: 551.69 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs//strobealign_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_2974659795_000002|2974659795|2974659795\tLN:6543\n",
      "Found 808 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 4920741it [00:08, 604464.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for x_mapper...\n",
      "File size: 3.06 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.001/raw_outputs//x_mapper_output.sam exists\n",
      "first line of sam file @CO\tSequence Alignment Map\n",
      "second line of sam file @CO\tFormat version, group order\n",
      "Found 808 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 19061it [00:00, 115980.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 975,589,515 alignments from 10 tools\n",
      "  Unique spacers: 3,882,812, contigs: 808\n",
      "\n",
      "=== Loading fraction 0.005 ===\n",
      "  Loading 11 tools: blastn, bowtie1, bowtie2, indelfree_bruteforce, indelfree_indexed, lexicmap, minimap2, mummer4, sassy, strobealign, x_mapper\n",
      "\n",
      "Reading results for blastn...\n",
      "File size: 5.80 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//blastn_output.tsv exists\n",
      "\n",
      "Reading results for bowtie1...\n",
      "File size: 498.79 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//bowtie1_output.sam exists\n",
      "first line of sam file @HD\tVN:1.0\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_3300006944_000023|3300006944|Ga0099823_1018790\tLN:6647\n",
      "Found 1907 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 3901347it [00:03, 1275492.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for bowtie2...\n",
      "File size: 501.34 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//bowtie2_output.sam exists\n",
      "first line of sam file @HD\tVN:1.5\tSO:unsorted\tGO:query\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_3300006944_000023|3300006944|Ga0099823_1018790\tLN:6647\n",
      "Found 1907 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 3894198it [00:03, 1204459.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for indelfree_bruteforce...\n",
      "File size: 278.74 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//indelfree_bruteforce_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_3300006944_000023|3300006944|Ga0099823_1018790\tLN:6647\n",
      "Found 1907 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 1823109it [00:05, 309991.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for indelfree_indexed...\n",
      "File size: 44.94 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//indelfree_indexed_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_3300006944_000023|3300006944|Ga0099823_1018790\tLN:6647\n",
      "Found 1907 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 275357it [00:01, 162786.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for lexicmap...\n",
      "File size: 0.00 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//lexicmap_output.tsv exists\n",
      "\n",
      "Reading results for minimap2...\n",
      "File size: 0.13 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//minimap2_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\tGO:query\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_3300006944_000023|3300006944|Ga0099823_1018790\tLN:6647\n",
      "Found 1907 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 9it [00:00, 8840.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for mummer4...\n",
      "File size: 10.50 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//mummer4_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_3300006944_000023|3300006944|Ga0099823_1018790\tLN:6647\n",
      "Found 1907 SQ lines, 1 PG lines\n",
      "SAM file needs fixing\n",
      "Rewriting HD line for mummer file\n",
      "SAM file has been fixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 62131it [00:00, 238522.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for sassy...\n",
      "File size: 438791.28 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//sassy.tsv exists\n",
      "Starting DuckDB Pipeline (Writing to: /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs/sassy_parsed_20260105.parquet)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a1536762af4505ae54cf073ecf4ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading new Parquet file into Polars...\n",
      "\n",
      "Reading results for strobealign...\n",
      "File size: 918.29 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//strobealign_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_3300006944_000023|3300006944|Ga0099823_1018790\tLN:6647\n",
      "Found 1907 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 7115517it [00:16, 431905.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for x_mapper...\n",
      "File size: 7.37 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.005/raw_outputs//x_mapper_output.sam exists\n",
      "first line of sam file @CO\tSequence Alignment Map\n",
      "second line of sam file @CO\tFormat version, group order\n",
      "Found 1907 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 45624it [00:00, 210035.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 2,869,184,123 alignments from 10 tools\n",
      "  Unique spacers: 3,882,812, contigs: 1,907\n",
      "\n",
      "=== Loading fraction 0.01 ===\n",
      "  Loading 11 tools: blastn, bowtie1, bowtie2, indelfree_bruteforce, indelfree_indexed, lexicmap, minimap2, mummer4, sassy, strobealign, x_mapper\n",
      "\n",
      "Reading results for blastn...\n",
      "File size: 12.27 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs//blastn_output.tsv exists\n",
      "\n",
      "Reading results for bowtie1...\n",
      "File size: 508.05 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs//bowtie1_output.sam exists\n",
      "first line of sam file @HD\tVN:1.0\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_638276392_000001|638276392|638276587\tLN:158482\n",
      "Found 3815 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 3934511it [00:03, 1127161.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for bowtie2...\n",
      "File size: 508.94 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs//bowtie2_output.sam exists\n",
      "first line of sam file @HD\tVN:1.5\tSO:unsorted\tGO:query\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_638276392_000001|638276392|638276587\tLN:158482\n",
      "Found 3815 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 3915428it [00:03, 1136318.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for indelfree_bruteforce...\n",
      "File size: 491.52 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs//indelfree_bruteforce_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_638276392_000001|638276392|638276587\tLN:158482\n",
      "Found 3815 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 3195833it [00:10, 295874.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for indelfree_indexed...\n",
      "File size: 98.10 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs//indelfree_indexed_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_638276392_000001|638276392|638276587\tLN:158482\n",
      "Found 3815 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 600298it [00:03, 169481.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for lexicmap...\n",
      "File size: 0.00 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs//lexicmap_output.tsv exists\n",
      "\n",
      "Reading results for minimap2...\n",
      "File size: 0.27 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs//minimap2_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\tGO:query\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_638276392_000001|638276392|638276587\tLN:158482\n",
      "Found 3815 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 46it [00:00, 22876.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for mummer4...\n",
      "File size: 23.01 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs//mummer4_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_638276392_000001|638276392|638276587\tLN:158482\n",
      "Found 3815 SQ lines, 1 PG lines\n",
      "SAM file needs fixing\n",
      "Rewriting HD line for mummer file\n",
      "SAM file has been fixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 136175it [00:00, 245644.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading results for sassy...\n",
      "File size: 852602.37 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs//sassy.tsv exists\n",
      "Starting DuckDB Pipeline (Writing to: /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs/sassy_parsed_20260105.parquet)...\n",
      "Failed to process Sassy file: Query interrupted\n",
      "\n",
      "Reading results for strobealign...\n",
      "File size: 1587.18 MB\n",
      " output file  /clusterfs/jgi/scratch/science/metagen/neri/code/blits/spacer_bench/results/real_data/subsamples/fraction_0.01/raw_outputs//strobealign_output.sam exists\n",
      "first line of sam file @HD\tVN:1.6\tSO:unsorted\n",
      "second line of sam file @SQ\tSN:IMGVR_UViG_638276392_000001|638276392|638276587\tLN:158482\n",
      "Found 3815 SQ lines, 1 PG lines\n",
      "SAM file looks good, no changes needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing SAM file: 113576it [00:00, 379871.29it/s]"
     ]
    }
   ],
   "source": [
    "# Load results from all fractions\n",
    "all_results = {}\n",
    "fractions = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "# fractions = [0.001]#, 0.005] #, 0.01, 0.05, 0.1] # starting small\n",
    "\n",
    "for frac in fractions:\n",
    "    print(f\"\\n=== Loading fraction {frac} ===\")\n",
    "    frac_dir = f\"{base_dir}/fraction_{frac}\"\n",
    "    contigs_file = f\"{frac_dir}/subsampled_data/subsampled_contigs.fa\"\n",
    "    \n",
    "    # Only load completed tools\n",
    "    completed_tools = completion_status[frac]['completed']\n",
    "    if not completed_tools:\n",
    "        print(f\"  No completed tools for fraction {frac}, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Load tool configurations\n",
    "    tools = load_tool_configs(\n",
    "        results_dir=frac_dir,\n",
    "        threads=8,\n",
    "        contigs_file=contigs_file,\n",
    "        spacers_file=spacers_file\n",
    "    )\n",
    "    \n",
    "    # Filter to only completed tools\n",
    "    tools_to_load = {k: v for k, v in tools.items() if k in completed_tools}\n",
    "    print(f\"  Loading {len(tools_to_load)} tools: {', '.join(tools_to_load.keys())}\")\n",
    "    \n",
    "    # Read results with max_mismatches filter\n",
    "    try:\n",
    "        results_df = read_results(\n",
    "            tools_to_load,\n",
    "            max_mismatches=MAX_MISMATCHES+2, #tool reported, not validated for the scalling tests\n",
    "            spacer_lendf=spacer_lendf,\n",
    "            ref_file=contigs_file,\n",
    "            threads=8,\n",
    "        )\n",
    "        \n",
    "        # Add fraction column\n",
    "        results_df = results_df.with_columns(pl.lit(frac).alias('fraction'))\n",
    "        results_df.write_parquet(f'results/real_data/subsamples_analysis/alignments_fraction_{frac}.parquet')\n",
    "        \n",
    "        all_results[frac] = results_df\n",
    "        print(f\"  Loaded {results_df.height:,} alignments from {results_df['tool'].n_unique()} tools\")\n",
    "        print(f\"  Unique spacers: {results_df['spacer_id'].n_unique():,}, contigs: {results_df['contig_id'].n_unique():,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading results: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Loaded results from {len(all_results)} fractions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.3 ms, sys: 18.5 ms, total: 60.8 ms\n",
      "Wall time: 11.7 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # Load results from all fractions\n",
    "# # fractions = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "# all_results = {0.001 :pl.read_parquet(f'results/real_data/subsamples_analysis/alignments_fraction_0.001.parquet')\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_results\u001b[49m  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_results' is not defined"
     ]
    }
   ],
   "source": [
    "all_results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = [0.005] #, 0.01, 0.05, 0.1] # starting small\n",
    "\n",
    "for frac in fractions:\n",
    "    print(f\"\\n=== Loading fraction {frac} ===\")\n",
    "    frac_dir = f\"{base_dir}/fraction_{frac}\"\n",
    "    contigs_file = f\"{frac_dir}/subsampled_data/subsampled_contigs.fa\"\n",
    "    \n",
    "    # Only load completed tools\n",
    "    completed_tools = completion_status[frac]['completed']\n",
    "    if not completed_tools:\n",
    "        print(f\"  No completed tools for fraction {frac}, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Load tool configurations\n",
    "    tools = load_tool_configs(\n",
    "        results_dir=frac_dir,\n",
    "        threads=8,\n",
    "        contigs_file=contigs_file,\n",
    "        spacers_file=spacers_file\n",
    "    )\n",
    "    \n",
    "    # Filter to only completed tools\n",
    "    tools_to_load = {k: v for k, v in tools.items() if k in completed_tools}\n",
    "    print(f\"  Loading {len(tools_to_load)} tools: {', '.join(tools_to_load.keys())}\")\n",
    "    \n",
    "    # Read results with max_mismatches filter\n",
    "    try:\n",
    "        results_df = read_results(\n",
    "            tools_to_load,\n",
    "            max_mismatches=MAX_MISMATCHES+2, #tool reported, not validated for the scalling tests\n",
    "            spacer_lendf=spacer_lendf,\n",
    "            ref_file=contigs_file,\n",
    "            threads=8,\n",
    "        )\n",
    "        \n",
    "        # Add fraction column\n",
    "        results_df = results_df.with_columns(pl.lit(frac).alias('fraction'))\n",
    "        results_df.write_parquet(f'results/real_data/subsamples_analysis/alignments_fraction_{frac}.parquet')\n",
    "        \n",
    "        all_results[frac] = results_df\n",
    "        print(f\"  Loaded {results_df.height:,} alignments from {results_df['tool'].n_unique()} tools\")\n",
    "        print(f\"  Unique spacers: {results_df['spacer_id'].n_unique():,}, contigs: {results_df['contig_id'].n_unique():,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading results: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Loaded results from {len(all_results)} fractions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Fraction Analysis (No Aggregation)\n",
    "\n",
    "Analyze each fraction separately since they're stratified samples from the same dataset and are not independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each fraction separately (they are NOT independent samples)\n",
    "# For each fraction, we'll compute summary stats\n",
    "\n",
    "per_fraction_stats = {}\n",
    "\n",
    "for frac, results_df in all_results.items():\n",
    "    print(f\"\\n=== Fraction {frac} Statistics ===\")\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"Total alignments: {results_df.height:,}\")\n",
    "    print(f\"Unique spacers: {results_df['spacer_id'].n_unique():,}\")\n",
    "    print(f\"Unique contigs: {results_df['contig_id'].n_unique():,}\")\n",
    "    print(f\"Tools: {results_df['tool'].n_unique()}\")\n",
    "    \n",
    "    # Per-tool summary\n",
    "    tool_summary = results_df.group_by('tool').agg([\n",
    "        pl.col('spacer_id').n_unique().alias('n_unique_spacers'),\n",
    "        pl.col('contig_id').n_unique().alias('n_unique_contigs'),\n",
    "        pl.len().alias('n_total_alignments'),\n",
    "        pl.col('mismatches').mean().alias('mean_mismatches'),\n",
    "        pl.col('mismatches').median().alias('median_mismatches'),\n",
    "        (pl.col('mismatches') == 0).sum().alias('n_perfect_matches'),\n",
    "    ]).sort('n_unique_spacers', descending=True)\n",
    "    \n",
    "    per_fraction_stats[frac] = tool_summary\n",
    "    print(f\"\\nTop 5 tools by unique spacers:\")\n",
    "    print(tool_summary.head(5))\n",
    "\n",
    "# Display all stats\n",
    "print(\"\\n\\n=== Summary Table: All Fractions ===\")\n",
    "for frac in sorted(per_fraction_stats.keys()):\n",
    "    print(f\"\\n--- Fraction {frac} ---\")\n",
    "    print(per_fraction_stats[frac])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalculate Alignments with Parasail for Deterministic Mismatch Counts\n",
    "\n",
    "The tool-reported mismatches can vary. We'll recalculate them deterministically using parasail.\n",
    "This follows the same workflow as the original full-dataset notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For each fraction, recalculate alignments\n",
    "recalculated_results = {}\n",
    "\n",
    "for frac, results_df in all_results.items():\n",
    "    print(f\"\\n=== Recalculating alignments for fraction {frac} ===\")\n",
    "    frac_dir = f\"{base_dir}/fraction_{frac}\"\n",
    "    contigs_file = f\"{frac_dir}/subsampled_data/subsampled_contigs.fa\"\n",
    "    \n",
    "    # Get unique regions (spacer-contig pairs with coordinates)\n",
    "    unique_regions = results_df.select([\n",
    "        \"spacer_id\", \"contig_id\", \"strand\", \"start\", \"end\"\n",
    "    ]).unique()\n",
    "    \n",
    "    print(f\"Unique regions to verify: {unique_regions.height:,}\")\n",
    "    \n",
    "    # Populate with spacer sequences\n",
    "    print(\"  Loading spacer sequences...\")\n",
    "    unique_regions = populate_pldf_withseqs_needletail(\n",
    "        seqfile=spacers_file,\n",
    "        pldf=unique_regions,\n",
    "        chunk_size=2000000,\n",
    "        reverse_by_strand_col=False,\n",
    "        trim_to_region=False,\n",
    "        idcol=\"spacer_id\",\n",
    "        seqcol=\"spacer_seq\"\n",
    "    )\n",
    "    \n",
    "    # Populate with contig sequences (trimmed to region)\n",
    "    print(\"  Loading contig sequences...\")\n",
    "    unique_regions = populate_pldf_withseqs_needletail(\n",
    "        seqfile=contigs_file,\n",
    "        trim_to_region=True,\n",
    "        reverse_by_strand_col=True,\n",
    "        chunk_size=200000,\n",
    "        pldf=unique_regions,\n",
    "        idcol=\"contig_id\",\n",
    "        start_col=\"start\",\n",
    "        end_col=\"end\",\n",
    "        strand_col=\"strand\",\n",
    "        seqcol=\"contig_seq\"\n",
    "    )\n",
    "    \n",
    "    # Recalculate mismatches using parasail\n",
    "    print(\"  Recalculating mismatches with parasail...\")\n",
    "    recalced = test_alignment_polars(\n",
    "        results=unique_regions,\n",
    "        return_deviations=False,\n",
    "        ignore_region_strands=True\n",
    "    )\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    recalced = recalced.rename({\"alignment_test\": \"recalced_mismatches\"})\n",
    "    \n",
    "    # Join back with original results\n",
    "    results_with_recalc = results_df.join(\n",
    "        recalced[[\"spacer_id\", \"contig_id\", \"strand\", \"start\", \"end\", \n",
    "                  \"spacer_seq\", \"contig_seq\", \"recalced_mismatches\"]],\n",
    "        on=[\"spacer_id\", \"contig_id\", \"strand\", \"start\", \"end\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Rename original mismatches for clarity\n",
    "    results_with_recalc = results_with_recalc.rename({\n",
    "        \"mismatches\": \"tool_reported_mismatches\"\n",
    "    }).rename({\n",
    "        \"recalced_mismatches\": \"mismatches\"\n",
    "    })\n",
    "    \n",
    "    # Check for deviations\n",
    "    results_with_recalc = results_with_recalc.with_columns(\n",
    "        (pl.col(\"mismatches\") - pl.col(\"tool_reported_mismatches\")).alias(\"deviation\")\n",
    "    )\n",
    "    \n",
    "    n_deviations = results_with_recalc.filter(pl.col(\"deviation\") != 0).height\n",
    "    print(f\"  Alignments with deviations: {n_deviations:,} ({100*n_deviations/results_with_recalc.height:.2f}%)\")\n",
    "    \n",
    "    # Filter to max_mismatches after recalculation\n",
    "    results_with_recalc = results_with_recalc.filter(pl.col(\"mismatches\") <= MAX_MISMATCHES)\n",
    "    print(f\"  Alignments after filtering (≤{MAX_MISMATCHES} mismatches): {results_with_recalc.height:,}\")\n",
    "    \n",
    "    recalculated_results[frac] = results_with_recalc\n",
    "\n",
    "print(f\"\\n✓ Recalculated alignments for {len(recalculated_results)} fractions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated Per-Fraction Statistics (with Recalculated Mismatches)\n",
    "\n",
    "Now compute statistics using the recalculated mismatches from parasail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute statistics with recalculated mismatches\n",
    "updated_per_fraction_stats = {}\n",
    "\n",
    "for frac, results_df in recalculated_results.items():\n",
    "    print(f\"\\n=== Fraction {frac} (Recalculated Mismatches) ===\")\n",
    "    \n",
    "    # Per-tool summary\n",
    "    tool_summary = results_df.group_by('tool').agg([\n",
    "        pl.col('spacer_id').n_unique().alias('n_unique_spacers'),\n",
    "        pl.col('contig_id').n_unique().alias('n_unique_contigs'),\n",
    "        pl.len().alias('n_total_alignments'),\n",
    "        pl.col('mismatches').mean().alias('mean_mismatches'),\n",
    "        pl.col('mismatches').median().alias('median_mismatches'),\n",
    "        (pl.col('mismatches') == 0).sum().alias('n_perfect_matches'),\n",
    "        pl.col('deviation').mean().alias('mean_deviation_from_tool'),\n",
    "        (pl.col('deviation') != 0).sum().alias('n_with_deviation'),\n",
    "    ]).sort('n_unique_spacers', descending=True)\n",
    "    \n",
    "    updated_per_fraction_stats[frac] = tool_summary\n",
    "    display(tool_summary)\n",
    "\n",
    "# Save updated stats\n",
    "print(\"\\n✓ Updated statistics computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations: Comparing Tools Across Fractions\n",
    "\n",
    "Plot tool performance metrics across subsample sizes using the recalculated mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results/real_data/subsamples_analysis', exist_ok=True)\n",
    "# Combine stats from all fractions for plotting\n",
    "plot_data_list = []\n",
    "for frac in sorted(updated_per_fraction_stats.keys()):\n",
    "    stats_df = updated_per_fraction_stats[frac].with_columns(pl.lit(frac).alias('fraction'))\n",
    "    plot_data_list.append(stats_df)\n",
    "\n",
    "combined_stats = pl.concat(plot_data_list)\n",
    "\n",
    "# Plot 1: Number of unique spacers found per tool across fractions\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Plot tools in consistent order with assigned colors/markers\n",
    "for tool in TOOL_ORDER:\n",
    "    tool_data = combined_stats.filter(pl.col('tool') == tool)\n",
    "    if tool_data.height == 0:\n",
    "        continue\n",
    "    tool_data = tool_data.sort('fraction')\n",
    "    style = TOOL_STYLES.get(tool, {'color': 'gray', 'marker': 'o'})\n",
    "    \n",
    "    ax.plot(tool_data['fraction'].to_list(), \n",
    "            tool_data['n_unique_spacers'].to_list(), \n",
    "            marker=style['marker'], \n",
    "            color=style['color'],\n",
    "            label=tool, \n",
    "            linewidth=2, \n",
    "            markersize=8, \n",
    "            alpha=0.85)\n",
    "\n",
    "ax.set_xlabel('Subsample Fraction', fontsize=13)\n",
    "\n",
    "ax.set_ylabel('Number of Unique Spacers Found', fontsize=13)\n",
    "print(f\"✓ Saved unique spacers plot (≤{MAX_MISMATCHES} mismatches)\")\n",
    "\n",
    "ax.set_title(f'Tool Performance: Unique Spacers vs Subsample Size (Recalculated ≤{MAX_MISMATCHES} mismatches)', plt.show()\n",
    "\n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "plt.savefig('results/real_data/subsamples_analysis/unique_spacers_vs_fraction.png', dpi=300, bbox_inches='tight')\n",
    "ax.set_xscale('log')\n",
    "plt.savefig('results/real_data/subsamples_analysis/unique_spacers_vs_fraction.pdf', bbox_inches='tight')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10, framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3, which='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Number of unique contigs matched per tool across fractions\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Plot tools in consistent order with assigned colors/markers\n",
    "for tool in TOOL_ORDER:\n",
    "    tool_data = combined_stats.filter(pl.col('tool') == tool)\n",
    "    if tool_data.height == 0:\n",
    "        continue\n",
    "    tool_data = tool_data.sort('fraction')\n",
    "    style = TOOL_STYLES.get(tool, {'color': 'gray', 'marker': 'o'})\n",
    "    \n",
    "    ax.plot(tool_data['fraction'].to_list(), \n",
    "            tool_data['n_unique_contigs'].to_list(), \n",
    "            marker=style['marker'],\n",
    "            color=style['color'],\n",
    "            label=tool, \n",
    "            linewidth=2, \n",
    "            markersize=8,\n",
    "            alpha=0.85)\n",
    "\n",
    "ax.set_xlabel('Subsample Fraction', fontsize=12)\n",
    "ax.set_ylabel('Number of Unique Contigs Matched', fontsize=12)\n",
    "ax.set_title(f'Tool Performance: Unique Contigs Across Subsample Sizes (≤{MAX_MISMATCHES} mismatches)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "print(f\"✓ Saved contigs plot (≤{MAX_MISMATCHES} mismatches)\")\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.savefig('results/real_data/subsamples_analysis/contigs_by_fraction.png', dpi=150, bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/real_data/subsamples_analysis/contigs_by_fraction.pdf', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In the these selected subsampling sizes, the results of each tool appear consist (similar ratios compared to the same tool but the other size fractions).\n",
    "This suggests we should be able to extrapolate/assume that should we have the CPU time to run all tools on the entire dataset (no subsampling) the results would be qualitative similar (from tool vs tool comparison perspective)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
